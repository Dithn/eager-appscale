In this section we provide details of Cerebro's design. We explain its major components, their interactions and how the 
system works as a whole. Recall that the overarching theme of our solution is to combine program
static analysis data with cloud platform monitoring data to formulate an accurate performance model for the 
web APIs developed for a given cloud platform. Therefore, at very least Cerebro requires the following two components:

\begin{itemize}
\item A program static analysis component that can extract the sequence of cloud SDK operations invoked by a web API
code.
\item A monitoring agent that runs in the target cloud platform to monitor the performance of its individual cloud SDK
operations.
\end{itemize}
 
 \subsection{Program Static Analysis Component}
 The static analysis component analyzes the source code (or some intermediate representation of it), to identify
 the cloud SDK operations invoked by a given web API code. Since a web API code can only make a finite
 number of cloud SDK invocations, and since PaaS clouds only support a finite number of cloud
 SDK operations, it is possible to design an algorithm that
 extracts all cloud SDK invocations from any given web API code. 

The basic idea behind Cerebro's static analysis is to construct and walk the
 control flow graph (CFG) of the given code. Whenever the algorithm encounters a node that represents a function call,
 it checks whether the function call corresponds to a cloud SDK operation. If so the algorithm
adds it to the output of the analysis. At the end of the analysis, the algorithm outputs a list whose members are
sequences of cloud SDK operations. Each sequence of operations corresponds to a different
path of execution through the code.

Listing 1 shows the outline of the basic program analysis algorithm used by Cerebro. 
Constructing the CFG from a given program
is a common problem with many efficient solutions. Graph traversal is performed in the depth-first 
fashion to ensure that the algorithm walks each path of execution to the end of the program, before picking up on
a new path. The algorithm marks the nodes in the CFG as it visits them to ensure that the graph traversal does not get stuck in loops. 

If the algorithm detects any function call nodes that correspond to functions in the user's code, the algorithm
starts analyzing the code of the target functions recursively. This effectively turns our analysis into an inter procedural
CFG analysis. Results obtained from analyzing user-implemented functions can be cached to avoid
having to analyze the same function more than once. Note that the algorithm simply appends the results of
analyzing user-implemented functions to the current sequence of cloud SDK invocations. This ensures that the final output of the
analysis contains cloud SDK invocation sequences spanning across all the relevant functions in the code. 
In other words, the operation sequences in the final output may cross function boundaries.
Since any web API considered for analysis must have a finite amount of code, as long as
we mark the visited nodes in the CFG, and keep track of the functions that we have already analyzed, this
analysis is guaranteed to terminate with results.

In Cerebro we do not recursively analyze any of the cloud
SDK operations or any third party library calls. 
Statically analyzing the internals of cloud SDK invocations is
unnecessary since we intend to build a performance model for web APIs where
the smallest unit of operation is a cloud SDK call (we simply do not need to dig any deeper). As for third 
party libraries, we assume they do not contain any cloud SDK invocations -- a reasonable assumption 
regarding most third party libraries that are generic and intended to run on a variety of target runtimes. 
 
Cerebro's static analysis is mostly comprised of well-understood, general purpose program analysis techniques.
 Perhaps the only application-specific element here is the method used to check function call nodes for cloud SDK invocations.
 In the worst case this check can be implemented as a table lookup. That is, we maintain a table of all possible cloud
 SDK operations, and check whether each function call
 corresponds to an entry in the table. In real world implementations there are other more efficient methods that
 can be employed to solve this problem. For instance some PaaS clouds use a special naming convention to label
 their cloud SDK operations. 
 In such a scenario we can simply check whether the function calls in CFG nodes match the
 desired pattern. 
 
 \subsection{Handling Loops}
The algorithm in listing 1 is only meant as an outline for a minimalistic program analysis that can be performed
within Cerebro. If needed more sophisticated analyses can be incorporated into this algorithm to extract more
useful information regarding the cloud SDK invocations. For example, we can perform a loop extraction on the
CFG to identify the loops in the code, and tag the cloud SDK invocations in the output to indicate which of them
are executed inside loops. In such an implementation, the output of the static analysis will not be a simple
list of cloud SDK invocation sequences. Rather, it will be a list of \textit{annotated} cloud SDK invocation sequences.

When there are cloud SDK invocations present inside loops, it would be useful to know how many times those loops
are going to execute. Clearly, any performance model based on cloud SDK calls made by a web API code,
needs to account for the repeated execution of cloud SDK calls inside loops. If the 
loops in question are data-independent (i.e. the iteration count does not depend on the size of the data processed 
by the code), we can use an static loop bound estimator to determine how many times the loops are going to iterate.
This can be done for each loop extracted during our CFG analysis, and the estimated loop bounds can be added to the
analysis output as annotations.

However, as indicated by our survey results, loops are fairly uncommon in web API codes developed for PaaS clouds. When
they are present, they usually iterate over some dataset (i.e. data-dependent). Such loops cannot
be accurately predicted using static analysis methods. But survey results also show us that
most of the time cloud web API codes iterate over datasets loaded from the underlying datastore of the PaaS.
We can use this as a heuristic to bound the iteration count of data-dependent loops. Typically, application developers
have an approximate idea of how large their database will be once their code is in production. When we encounter a data-dependent
loop in the CFG that we cannot accurately predict using a static loop bound estimator, we can simply
prompt the developer to enter a reasonable maximum size for the underlying database (i.e. the maximum number of
records/entities that may be returned from the datastore). We can
use these developer-specified values as upper bounds for the loop iteration count. 
This information can also be added to the final outcome of the static analysis as annotations.

\subsection{Watchtower: Cloud Platform Monitoring Agent}
Now we discuss Watchtower, the proposed monitoring agent for tracking the performance of individual
cloud SDK operations over time. This component can be an integral part of the PaaS cloud that
monitors cloud SDK operations from within, or it can be another application deployed on the PaaS
that periodically benchmarks the cloud SDK operations from the outside. Regardless of how it is
implemented, it must cater for two requirements:

\begin{itemize}
\item Watchtower should always be active, and collect data as long as the cloud platform is available for serving web API requests.
\item Watchtower should periodically measure the time taken by individual cloud SDK operations, and arrange the gathered data into time series (one time series per cloud SDK operation).
\end{itemize}

In addition to the above requirements, Watchtower should also expose some web APIs of its own 
so that other components in Cerebro can query the Watchtower to retrieve the collected time series data. Also,
it should keep the collected time series data in a persistence storage for durability. The most logical
place to store this data would be the underlying datastore of the PaaS itself, since it is already designed
for high scalability. To avoid unbounded accumulation of time series data, Watchtower can discard the old
measurements once a certain amount of time has elapsed. For example, it can periodically clean up
all data points that are more than a month old. It is fair to assume that the current performance of web APIs
is not influenced by how the cloud SDK operations behaved a month ago. 

The frequency at which
Watchtower collects data determines how often Cerebro can generate SLA predictions for web APIs. Practically
speaking, it is sensible to benchmark the cloud SDK operations once every few minutes (e.g. 1-10 minutes). It does not make
sense to collect data any more frequently than that, since we naturally expect each Cerebro predicted SLA to 
hold correct for a time period longer than a few minutes.

In order to make SLA predictions regarding codes that include data-dependent loops, we also use Watchtower
to benchmark some common iterative cloud SDK operations. 
Watchtower executes a series of iterative datastore reads,
while varying the result set size, to measure the time required to loop through different sized result sets. These
measurements are also stored as time series data, where each result set size gets its own time series. 
It is not necessary to benchmark all possible result set sizes. Rather, Watchtower should only benchmark a
handful of result set sizes  (e.g. 1, 1000 and 1000000) that are representative of production workloads.

\subsection{Making SLA Predictions}
So far we have explained our approach for statically analyzing the web API codes to extract the sequence
of cloud SDK operations, and periodically benchmarking the performance of individual cloud SDK
operations. Next step is to combine these two pieces of information and predict the execution of the
web API code. For this purpose we employ a tried and tested machine learning technique called
QBETS (Queue Bounds Estimation from Time Series). 

QBETS is a non-parametric time series analysis method that looks at past time series data, and predicts
an upper bound on a specific percentile at a fixed level of confidence. A QBETS analysis requires three inputs:

\begin{enumerate}
\item A time series of data generated by a continuous experiment
\item The percentile for which an upper bound should be predicted ($p \in [1..99]$)
\item The upper confidence level of the prediction ($c \in (0,1)$)
\end{enumerate}

QBETS uses this information to predict an upper bound for the $p$-th percentile of the time series.
The predicted value has a probability of $0.01p$ of being greater than or equal to the next data point that
will be added to the time series by the continuous experiment. 
The upper confidence level $c$ serves as a conservative
bound on the predictions. That is, predictions made with an upper confidence level of $c$ will overestimate
the true percentile with a probability of $1-c$. This confidence guarantee is necessary because 
QBETS does not determine the 
percentiles of the time series precisely, but only estimates them. 

To further clarify what QBETS does, assume a continuous experiment that periodically measures the
response time of a web API. This results in a time series of response time data. Now suppose at time $t$,
we run QBETS on the time series data collected so far with $p=95$ and $c=0.01$. The prediction returned
by QBETS has a 95\% chance of being greater than or equal to the next response time value measured
by our experiment after time $t$. Since $c=0.01$, the predicted value has a 99\% chance of
overestimating the true 95th percentile of the time series.

We find QBETS to be an ideal fit for our work due to several reasons. 
\begin{itemize}
\item QBETS works with time series data. Since
cloud SDK benchmarking data can be easily represented as time series,
they are already highly amenable for QBETS analysis. 
\item QBETS makes predictions regarding the
future outcomes of an experiment by looking at the past outcomes -- an idea that resonates well with our
goal of predicting future API response times from past cloud SDK benchmarking data. 
\item Response time
SLAs of web APIs should be specified with exact correctness probabilities and confidence levels for
them to be useful. Predictions made by QBETS meet these requirements well. 
\item QBETS is 
simple, efficient and has been applied successfully to analyze a wide range of time series data in the past.
More specifically, it has been tested with both autocorrelating and non-autocorrelating time series data.
\end{itemize}