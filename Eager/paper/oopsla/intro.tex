Web services, service oriented architectures, and cloud platforms together have
revolutionized the way developers engineer and deploy software.
Using the web service model, developers ``mash up'' content and functionality 
from remote, web-accessible services exposed via application programming interfaces (APIs)
to create new web-accessible services and applications (software-as-a-service or web APIs).  
This development model expedites implementation since developers can leverage the 
software engineering and maintenance of others.
%, and increases programmer productivity. 
Moreover, the advent of cloud platform as-a-service (PaaS) technologies 
simplify and automate deployment and management
of web APIs in both public (managed) and private settings.  

As a result, web APIs are rapidly 
proliferating.  At the time of this writing, 
the ProgrammableWeb~\cite{pweb} indexes over $13,000$
publicly available web APIs.
These APIs increasingly employ the REST (Representational State Transfer) 
architectural style~\cite{Fielding:2000:ASD:932295}, and target both
commercial (e.g. advertising, shopping, travel, etc.) and non-commercial
(e.g. IEEE~\cite{ieeeapis}, UC Berkeley~\cite{ucbapis}, and the US White
House~\cite{whitehouseapis}) application domains.

Despite the many benefits, reusing services that are implemented
and maintained by others, also has its costs.  
In particular, new web APIs become dependent on the 
services they compose.  These dependencies
impact correctness, performance, and availability of the encapsulating 
web APIs -- for which the developer becomes accountable.  
Compounding the situation, the underlying services can and do change over time, typically
unbeknownced to the developers that programmatically access them from their web APIs.
Unfortunately, there is a dearth of tools that help developers reason about these 
dependencies throughout an application's 
lifecycle (i.e. development, deployment, and runtime).  Without such tools, 
programmers must resort to extensive, continuous, and costly, testing and profiling 
for all of the services that they integrate.

To address this need, we present Cerebro, a new approach that
\textit{statically} predicts the execution performance of web APIs that 
integrate services as part of their functionality.
To enable this, we employ the notion of service-level agreement (SLA) from 
public cloud computing systems such as Amazon Web Services (AWS)~\cite{amazon-aws-web} and 
Google App Engine~\cite{gae}.  SLAs are policies that specify
what a developer can expect from a service in terms of availability or error rate,
typically before they receive a financial credit for paid
use of the service~\cite{aws-ec2-sla,aws-s3-sla,aws-rds-sla,gae-sla,gcs-sla}.
For example, AWS makes its Elastic Compute Cloud (EC2) and Elastic Block Store (EBS) 
available with a monthly uptime percentage 
of at least 99.95\%; Google makes Big Query and and App Engine services (e.g. the 
Bigtable-based datastore) available with monthly uptime percentage of at least 
99.95\% where downtime is determined by a 5\% and 10\% error rate, respectively.
Cerebro extends this notion of SLA to the execution time (response time) 
of web APIs that are deployed via (i.e. hosted by) PaaS
technologies (e.g. App Engine, 
AppScale~\cite{6488671}, Azure~\cite{azure-web}, etc.).
For example, a Cerebro SLA says that an API operation will respond to a HTTP request
within 100ms at least 95\% of the time.

We target cloud platforms (public and private) as our web API and Cerebro 
runtime system given their popularity and wide spread use~\cite{paas-growth}.
For example, there are over four million active App Engine web APIs that 
can execute on Google's public cloud or over AppScale (an open source, private 
cloud version of App Engine) without modification.  A PaaS provides developers 
with a collection of commonly used, scalable services,
that the platform defines and exports via a cloud software 
development kit (cloud SDK).  These services are fully managed and covered under 
availability SLAs by the platform. For example, the services 
of App Engine and AppScale 
include distributed NoSQL datastores, SQL databases, task management, 
and data caching, among others. 

Cerebro predicts execution time SLAs for a web API by combining static analysis
of the program with dynamic performance sampling of the cloud services 
in the platform that the web API uses, as depicted in Figure~\ref{fig:overview}.
Cerebro uses static analysis to identify the cloud SDK operations
that dominate the execution time of web APIs.  Cerebro also integrates a nonparametric
prediction tool that we have developed in prior work for a completely different 
purpose: batch queue prediction in high-performance computing 
systems~\cite{Nurmi:2007:QQB:1791551.1791556}. Cerebro interacts with this tool
dynamically to estimate an upper bound on the execution time of each service operation, 
which it combines with its static analysis to forecast an execution SLA for the web API.

Because platform behavior and service implementations can change,
Cerebro's predictions necessarily have a lifetime.  
As part of this paper, we investigate
the effective lifetime of these predictions.  When such changes occur,
Cerebro can be reinvoked to establish new SLAs for any deployed web API.  Moreover,
the Cerebro sampling framework can be used to identify potential SLA violations
so that they can be avoided via mechanisms such 
as web API rate limiting and resource acquisition.


We have implemented Cerebro for both the App Engine public PaaS and 
the AppScale private PaaS. Given its modular design and this experience, 
we believe that it can be easily added to any PaaS system.
We use our prototypes to evaluate the correctness and accuracy of Cerebro 
as well as the tightness
of the bounds it predicts (i.e. the difference between the prediction and 
the actual API execution times) using open source App Engine applications (web APIs).  
We also investigate the duration over which 
these predictions hold.  We find that Cerebro is able to achieve its SLAs with 
very high accuracy and that the predictions hold from 1.4 to over 24 hours.  
We also find that the high variability of the public PaaS due to multitenency
and massive scale requires that Cerebro be more conservative in its predictions
(i.e. they are less tight than those for the AppScale private, single tenent cloud), 
to achieve the same level of accuracy.  Finally, because Cerebro provides this 
analysis statically wrt web API development, 
it precludes the need for deployment, load testing, and
instrumentation of the web APIs being analyzed.

In the sections that follow, we first overview our approach and our assumptions 
in Section~\ref{sec:approach}.   We then
present the results of a performance analysis that we have performed which provides
insight into the performance characteristics of PaaS 
applications (Section~\ref{sec:survey}).  
In Section~\ref{sec:design}
and Section~\ref{sec:prototype_impl}, we explain the architecture and 
prototype of Cerebro, respectively.  We then 
present our empirical evaluation of the Cerebro prototype in 
Section~\ref{sec:results}.
Finally,  we discuss related work (Section~\ref{sec:related_work}) and 
conclude (Section~\ref{sec:conclusions}).

%Each prediction can be configured by developers or 
%administrators if desired in terms of success probability and conservativeness.
%Success probability is the fraction of API invocations whose execution 
%times are less than or equal to the predicted upper bound.
%Conservativeness is the degree to which 
%Cerebro is overestimating the upper bound on execution time, e.g. due to 
%high variability in the performance of platform services.
%The combination of these two metrics 
%enable API developers to use Cerebro to predict performance SLAs for their
%web APIs. 

%Cerebro is fully automated and requires no developer intervention.
%It also precludes the need for deployment, load testing, and
%instrumentation of the web APIs being analyzed. Our intention is for software
%engineers to invoke Cerebro during development to help them reason about the performance
%implications of their web APIs and at deployment time to establish an SLA for their
%users or customers.
