Web services and service oriented architecture (SOA) have
revolutionized the way developers implement software applications.
Instead of implementing all the functionality from the scratch, developers
increasingly offload ({\em i.e.} as a ``mash-up'') as much application functionality 
as possible to remote,
web-accessible services, each of which exports its own application programming
interface (API). Thus, a modern application often combines local program logic
with calls to remote web APIs.
This approach significantly reduces both the programming and
the maintenance workload associated with the application.
Moreover, by accessing common services via APIs, developers avoid ``re-inventing the
wheel''.

As a result, web-accessible APIs and the software implementations to which
they provide access to are rapidly proliferating.
At the time of this writing, 
ProgrammableWeb~\cite{pweb}, a popular web API index, lists more than $13,000$
publicly available web APIs.
These APIs increasingly employ the REST (Representational State Transfer) architectural style and 
many of them target commerce-oriented applications (e.g. advertising, shopping, travel, etc.).
However, several non-commercial entities have also recently published web 
APIs, e.g. IEEE~\cite{ieeeapis}, UC Berkeley~\cite{ucbapis}, and the US White
House~\cite{whitehouseapis}. 

Web APIs are most useful when they are published with well defined service-level agreements (SLA). 
An API's SLA clearly outlines the performance characteristics and other non-functional 
properties of the API. It is a guarantee given by the API provider to the API consumer on what can be
expected from a web API with regard to its performance and runtime behavior. An example SLA regarding
the response time of an API could be ``API responds under 100ms, 95\% of the time''.
Without a clear performance SLA it is difficult, if not impossible,
to use a web API for developing a wide range of applications like real-time applications, interactive
user-facing applications and mobile applications. Even in the case of implementing a generic desktop
application, the developers would naturally like to be able to reason about
the performance that can be expected from the application. If the web APIs invoked by the code do
not come with clear SLAs, such reasoning becomes impossible. Therefore it is an absolute
necessity that API providers always publish clear SLAs along with their web APIs. To
facilitate this requirement, platforms used to deploy web APIs should enable API providers to 
easily understand the performance SLAs that can be supported by the platform.

On a somewhat different note, platform-as-a-service (PaaS) clouds continue to garner 
popularity for their ability to simplify the process of developing web applications and
hosting web APIs for external users and programs. These cloud platforms provide the
programmers with two main benefits:

\begin{description}
\item[Reducing programming overhead] PaaS clouds provide a collection of powerful programming 
libraries and utilities (aka cloud software development kit, or cloud SDK), that make developing new applications 
and services easier.
\item[Reducing management overhead] PaaS clouds provide managed and monitored application deployment
environments, that guarantee scalable and high available operation of production applications under
changing conditions.
\end{description}

For these benefits, developers increasingly choose PaaS clouds as development platforms
and deployment targets for their applications and APIs. Consequently, the number of applications and 
APIs hosted in PaaS clouds have skyrocketed as of late. Google App Engine, one of the earliest
public PaaS cloud offerings, is the hosting platform for over a million applications. Some of the
well known commercial applications served from Google App Engine include BestBuy, Snapchat, 
and Sony Music. A lot of these applications also expose web APIs, so that other
programs (especially mobile apps), can interact with them.

Despite PaaS clouds being a preferred deployment target for web APIs, they do not assist the API
developers in any way to understand the SLAs that can be supported on deployed APIs. That is,
when a web API is deployed on a PaaS cloud, the cloud platform does not provide any feedback 
on how the API will perform (throughput, response time etc.). Additionally,
there are no tools that API developers can use at development-time to assess the performance
that can be expected from their API code when deployed into the production cloud environment.

The above limitations mean that API developers today have to roll out their API implementations into PaaS
clouds without clear performance SLAs. The only way to uncover this information is to subject the API
code to extensive load testing in the cloud platform, which takes time and financial resources
(running load tests on a PaaS cloud can incur significant usage costs). Even then, the resulting
performance SLAs may not be fully accurate due to errors, limitations and oversights in the load tests.
To solve this issue, ideally we should arm today's PaaS clouds with the ability to automatically assess and
predict the performance SLAs that can be supported on deployed web APIs, without having to
run any load tests. That would enable API providers to be informed about the performance
SLAs of their API codes, before they are ever used by the API consumers. This means
every API that goes into production can have a clear and accurate performance SLA from
day one.

To this end we propose Cerebro, a system that predicts the execution time SLAs of web APIs
deployed in PaaS clouds. Cerebro uses static analysis to identify the expensive cloud SDK operations
executed by web API codes. Then it analyzes historical performance data regarding cloud SDK
operations to predict upper bounds for web API execution times. All Cerebro predictions
are associated with configurable levels of success probability and conservativeness. The level of 
success probability is the fraction of API invocations whose execution times will be less than or equal to the
predicted upper bound. The level of conservativeness is an indication of by how much Cerebro
is overestimating the execution time upper bound. Such precision and completeness of results
imply that API developers can directly use Cerebro predictions as performance SLAs for their
API codes. Further to that, Cerebro is fully automated (i.e. no developer intervention necessary in
the prediction making process), and requires absolutely no load testing on the API codes. It can be
invoked while an API is being developed (at development-time), or just before an API is deployed
into the production cloud platform (at deployment-time). Cerebro can also be invoked on deployed
web APIs (at run-time) to periodically re-evaluate and revise the performance SLAs.

Cerebro's design is based on a hybrid approach that combines program static analysis with run-time
monitoring of cloud platforms. Static analysis provides insight to the structure and control flow of web
API codes. Through a survey involving a collection
of real world PaaS applications, we learn that web API codes developed for PaaS clouds have
some unique properties, that make them amenable for execution time assessment via static 
analysis. Periodic run-time monitoring of the cloud sheds light on how
the cloud platform has performed over time. Combination of these two aspects enables
us to construct an accurate and up-to-date performance model of the web API code, in light of the 
current and historical state of the underlying cloud platform. 

We note that Cerebro only predicts the
execution times of API codes. To turn these values into proper response time SLAs, we need to
add the network overhead within the API provider's network domain (time for request ingress
and response egress). In many cloud platforms, such network latency data are
known and well-understood. Therefore we believe that given a Cerebro prediction, it is trivial
for an API provider to turn it into an API response time SLA if necessary.

We implemented Cerebro for two cloud platforms -- Google App Engine public cloud, and AppScale
private cloud. Our experiments show that Cerebro is able to predict the execution time
of many different API implementations with very high accuracy. 
Further, we note that
predictions generated by Cerebro are very tight in most cases. That is, the predicted values do not
overestimate the actual API execution times by much. It is only when the APIs have highly variable 
performance characteristics, that Cerebro predicts conservative bounds. We show that this feature 
is necessary to ensure the desired accuracy levels in predictions.
We also show that Cerebro predictions
are valid for more than 24 hours on average, and for more than an hour at least 95\% of the time.