Web services and service oriented architecture (SOA) have
revolutionized the way developers implement software applications.
Instead of implementing all the functionality from the scratch, developers
increasingly offload ({\em i.e.} as a ``mash-up'') as much functionality 
as possible to remote,
web-accessible services, each of which exports its own application programming
interface (API). Thus, a modern application often combines local program logic
with calls to remote web APIs.
This approach significantly reduces both the programming and
the maintenance workload associated with the application.
Moreover, by reusing common functionality via APIs, developers avoid ``re-inventing the
wheel''.

As a result, web-accessible APIs and the software implementations to which
they provide access to are rapidly proliferating.
At the time of this writing, 
ProgrammableWeb~\cite{pweb}, a popular web API index, lists over $13,000$
publicly available web APIs.
These APIs increasingly employ the REST (Representational State Transfer) architectural style~\cite{Fielding:2000:ASD:932295} and 
many of them target commerce-oriented applications (e.g. advertising, shopping, travel, etc.).
However, several non-commercial entities have also recently published web 
APIs, e.g. IEEE~\cite{ieeeapis}, UC Berkeley~\cite{ucbapis}, and the US White
House~\cite{whitehouseapis}. 

Web APIs are most useful when they are published with well-defined service-level agreements (SLA). 
An SLA specifies the performance characteristics and other non-functional 
properties of an API. It is a guarantee given by the API provider to the API consumer on what can be
expected from a web API with regard to its performance and runtime behavior. An example SLA regarding
the response time of an API could be specified as: \textit{API responds under 100ms, at least 95\% of the time}.

Without a clear performance SLA it is difficult, if not impossible,
to use a web API to develop a wide range of applications like real-time applications, interactive
user-facing applications and mobile applications.
Developers typically prefer to be able to reason about
the performance of their programs. If the web APIs invoked by their code do
not come with clear SLAs, such reasoning becomes impossible. Therefore it is an absolute
necessity that API developers publish clear SLAs along with their web APIs. 

Despite the need, technologies used to host web APIs in today's world do not assist the API
developers in any way to understand the SLAs that can be supported on deployed APIs. That is,
when a web API is deployed on some platform, the platform does not provide any feedback 
on how the API will perform (throughput, response time etc.). Furthermore,
there are no tools that API developers can use at development-time to assess the performance
that can be expected from their API code when deployed into the production environment.
These limitations force developers to release web APIs without performance SLAs.

Some developers try to mitigate this problem by subjecting their API codes to 
extensive load testing. Results obtained
from such testing are used to draft SLAs for web APIs.
But this approach requires time and manpower. Furthermore, the resulting SLAs
may be erroneous due to various limitations and oversights in the testing process.
A more efficient and reliable solution to this problem is to 
arm the API deployment technologies with the ability to automatically assess and
predict the performance SLAs that can be supported on deployed web APIs. 
That would enable API providers to be informed about the performance
SLAs of their API codes, before they are ever used by the API consumers. 
%It allows every web API to have a clear performance SLA throughout its lifecycle.

To this end we propose Cerebro, a system that predicts the execution time SLAs of web APIs
deployed in platform-as-a-service (PaaS) clouds. We focus on PaaS clouds due to their
growing popularity as a technology for deploying web applications and APIs.
PaaS clouds provide the programmers with two main benefits:

\begin{description}
\item[Reducing programming overhead] PaaS clouds provide a collection of powerful programming 
interfaces (aka cloud software development kit, or cloud SDK), that make developing new applications 
easier.
\item[Reducing management overhead] PaaS clouds provide managed and monitored application deployment
environments, that guarantee scalable and high available operation of applications under changing conditions.
\end{description}

For these benefits, developers increasingly choose PaaS clouds as development platforms
and deployment targets for their applications and APIs. Consequently, the number of applications and 
APIs hosted on PaaS clouds has grown rapidly. Google App Engine (App Engine)~\cite{gae}, one of the earliest
public PaaS cloud offerings, hosts over four million applications. Some of the
well known commercial applications served from App Engine include BestBuy, Snapchat, 
and Sony Music. A lot of these applications also expose web APIs, so that other
programs (especially mobile apps), can interact with them. AppScale~\cite{6488671}, an open source PaaS cloud that
mimics App Engine, enables users to deploy any App Engine application in a private on-premise
cloud environment, without changing application code. 

Cerebro uses static analysis to identify the expensive cloud SDK operations
executed by web API codes. Then it analyzes historical performance data regarding cloud SDK
operations to predict upper bounds for web API execution times. All Cerebro predictions
are associated with a configurable level of success probability and conservativeness. The level of 
success probability is the fraction of API invocations whose execution times will be less than or equal to the
predicted upper bound. The level of conservativeness is an indication of by how much Cerebro
is overestimating the execution time upper bound. Such precision and completeness of results
enable API developers to directly use Cerebro predictions as performance SLAs of their
API codes.

We design Cerebro to be fully automated (i.e. no developer intervention necessary in
the prediction making process). It also does not require load testing on the API codes. Cerebro can be
invoked while an API is being developed (at development-time), or just before an API is deployed
into the production cloud platform (at deployment-time). It can also be invoked on deployed
web APIs (at run-time) to periodically re-evaluate and revise the performance SLAs.

Cerebro's design is based on a hybrid approach that combines program static analysis with run-time
monitoring of cloud platforms. Static analysis provides insight to the control flow of web
API codes. Through a survey involving a number
of real world PaaS applications, we learn that codes developed for PaaS clouds have
some unique properties, that make them amenable for execution time assessment via static 
analysis. Periodic run-time monitoring of the cloud sheds light on how
the cloud platform has performed over time. Combination of these two aspects enables
us to construct an accurate and up-to-date performance model of the web API code. 

%We note that Cerebro only predicts the
%execution times of API codes. To turn these predictions into proper response time SLAs, we need to
%add the network overhead within the API provider's network domain (time for request ingress
%and response egress). In many cloud platforms, such details regarding network latency are
%known and well-understood. Therefore we believe that given a Cerebro prediction, it is trivial
%for an API provider to turn it into an API response time SLA if necessary.

We implemented Cerebro for App Engine and AppScale.
Our experiments show that Cerebro is able to predict the execution time
of many different API implementations with very high accuracy. 
Further, we note that
predictions generated by Cerebro are very tight in most cases. That is, the predicted values do not
overestimate the actual API execution times by much. It is only when the APIs have highly variable 
performance characteristics, that Cerebro predicts conservative bounds. We show that this feature 
is necessary to ensure the desired accuracy levels in predictions.
We also show that Cerebro predictions
are valid for more than 24 hours on average, and for more than an hour at least 95\% of the time.

We organize the rest of the paper as follows. Section~\ref{sec:approach} outlines our approach towards
a solution, and the assumptions made in the process. Section~\ref{sec:survey}
presents the results of a survey that analyzes a collection of PaaS applications. Section~\ref{sec:design}
and section~\ref{sec:prototype_impl} explain the architecture and the prototype implementation of Cerebro.
Section~\ref{sec:results} presents the results we have obtained using Cerebro on two cloud platforms.
Finally, section~\ref{sec:related_work} discusses some of the related work, and section~\ref{sec:conclusions}
concludes the paper.