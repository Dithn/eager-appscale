Our research leverages a number of mature research areas in computer 
science and mathematics. These areas include static program analysis, 
cloud computing, time series analysis,
and SOA governance.

The problem of predicting execution time SLAs of web APIs 
is similar to worst-case execution
time (WCET) analysis~\cite{Wilhelm:2008:WEP:1347375.1347389,ermedahl2007loop,Sandberg:2006:FWF:1134650.1134666,Muchnick:1998:ACD:286076,Frost:2011:WAJ:2043910.2043916}. 
The objective of WCET analysis is to determine the maximum execution time of a software component in a given hardware platform. It is 
typically discussed in the context of real-time systems, where the developers should be able to document
and enforce precise hard real-time constraints on the execution time of programs. In order to save time, 
manpower and hardware resources, WCET analysis solutions are generally designed favoring static
analysis methods over software testing. We share similar concerns with regard to cloud platforms,
and strive to eliminate software testing in the favor of static analysis. 

Ermedahl et al describe SWEET~\cite{ermedahl2007loop}, a WCET analysis tool that make use of program slicing~\cite{Sandberg:2006:FWF:1134650.1134666},
 abstract interpretation~\cite{Cousot:1977:AIU:512950.512973} and invariant analysis~\cite{Muchnick:1998:ACD:286076} to determine the loop bounds and worst-case execution time 
 of a program. 
%Program slicing helps to reduce the amount of code and program states that need to be 
 %analyzed by SWEET. 
Program slicing used in this prior work to limit the amount of code being analyzed is similar in its goal to our focus on cloud SDK invocations.
 %SWEET uses abstract interpretation in interval and congruence domains to identify
 %the set of values that can be assigned to key control variables of a program. These sets are then
 %used to calculate exact loop bounds for most data-independent loops in the code. Invariant analysis  is
 %used to detect variables that do not change during the course of a loop iteration, and remove them from
 %the analysis thus further simplifying the loop bound estimation. 
Lokuceijewski et al propose 
 a similar WCET analysis using program slicing and abstract interpretation~\cite{Lokuciejewski:2009:FPS:1545006.1545064}. They additionally use a technique
called polytope models to speed up the analysis.  
%Frost et al have developed TetaJ, a WCET
 %tool for Java byte code programs~\cite{Frost:2011:WAJ:2043910.2043916}.
 
The corpus of research that covers the use of static analysis methods 
to estimate the execution time of software applications is 
extensive. Gulwani, Jain and Koskinen used two techniques named control-flow
 refinement and progress invariants to estimate the bounds for procedures with nested and multi-path loops~\cite{Gulwani:2009:CRP:1542476.1542518}.
 Gulwani, Mehra and Chilimbi proposed SPEED~\cite{Gulwani:2009:SPE:1480881.1480898}, a system that computes symbolic bounds for programs. This
 system makes use of user-defined quantitative functions to predict the bounds for loops iterating over
data structures like lists, trees and vectors. Our idea of using user-defined values to bound
 data-dependent loops (e.g. iterative datastore reads) is partly inspired by this concept.
 Bygde~\cite{bygde2010static} proposed a set of algorithms for predicting data-independent loops using abstract interpretation
 and element counting (a technique that was partly used in \cite{ermedahl2007loop}). 
Cerebro incorporates minor variations of these algorithms successfully due to their
simplicity.  
 
Cerebro makes use of and is similar to many of the execution time analysis 
systems discussed above.  However, there are also several key differences. 
For instance, Cerebro is focused on solving the
execution time prediction problem for PaaS-hosted web APIs. 
As we show in our characterization survey, such applications 
have a set of unique properties, that can be used to greatly simplify static analysis.
Also, Cerebro is designed to only work with web API codes. This makes designing 
a solution much more simpler but less general.
To handle the highly variable and evolving nature of
cloud platforms, Cerebro combines static analysis with runtime
monitoring of cloud platforms at the level of SDK operations. No other 
system provides such a hybrid approach to the best of our knowledge. 
Finally,
we use time series analysis~\cite{Nurmi:2007:QQB:1791551.1791556} 
to predict API execution time upper bounds with specific confidence
levels.

SLA management on service-oriented systems and cloud systems has been 
throughly researched
over the years. However, a lot of the existing work has focused on issues 
such as SLA monitoring~\cite{Michlmayr:2009:CQM:1657755.1657756,Tripathy:2011:MMS:1980822.1980832,Raimondi:2008:EOM:1453101.1453125,Bertolino:2007:SUS:1294904.1294914}, SLA negotiation~\cite{Mahbub:2011:PSN:2061042.2062022,Yaqub:2014:ONS:2680847.2681496,6546098}, and SLA modeling~\cite{Chau:2008:ASM:1463788.1463802,Stamou:2013:SGM:2516588.2516592,Skene:2004:PSL:998675.999422}. 
Some work has looked at incorporating a given SLA to the design of a system, and
then monitoring it at the runtime to ensure SLA compliant behavior~\cite{He:2013:TSC:2532443.2532449}. 
Our research takes a
different approach from such works, whereby it attempts to predict the performance SLAs for a
given web API. To the best of our knowledge, Cerebro is the first system to predict performance SLAs for web APIs developed for PaaS clouds.

A work that is similar to ours has been proposed by Ardagna, Damiani and Sagbo in~\cite{6649675}. 
The authors develop
a system for early estimation of service performance based on simulations. Given a STS
model (Symbolic Transitions System) of a service, their system is able to generate a simulation script, which
can be used to assess the performance of the service. STS models are a type of finite state automata. 
Further, they use probabilistic distributions with fixed parameters
to represent the delays incurred by various operations in the service. Cerebro is easier to use than this
system because we do not require API developers to construct any models of the web APIs. 
%They only need to provide the source code of the API implementations. 
Also, instead of using probabilistic distributions
with fixed parameters, Cerebro uses actual historical performance metrics of cloud SDK operations. This enables
Cerebro to generate more accurate results, that reflect the dynamic nature of the cloud platform.

In PROSDIN~\cite{Mahbub:2011:PSN:2061042.2062022}, a proactive service discovery and negotiation
framework, the SLA negotiation occurs during the service discovery phase. This is similar to how
Cerebro establishes an initial SLA with an API consumer, when the consumer subscribes to an API. PROSDIN also
establishes a fixed SLA validity period upon negotiation, and triggers an SLA renegotiation when this time period has 
elapsed. Cerebro on the other hand continuously monitors the cloud platform,
and periodically re-evaluates the response time SLAs of web APIs 
to determine when a re-negotiation is needed.
Similarly, researchers have investigated the notions of SLA brokering~\cite{6546098}, and the automatic SLA negotiation
between intelligent agents~\cite{Yaqub:2014:ONS:2680847.2681496}, ideas that can complement the
simple SLA negotiation model of Cerebro to make it more powerful and flexible.

Meryn~\cite{Dib:2013:MOS:2465823.2465825} is an SLA-driven PaaS system that attempts to maximize cloud
provider profit, while providing the best possible quality of service to the cloud users. It supports
SLA negotiation at application deployment, and SLA monitoring to detect
violations. However, it does not automatically determine what SLAs are
feasible or address SLA renegotiation, 
and employs a policy-based mechanism coupled
with a penalty cost charged against the cloud provider to
handle SLA violations. Also, Meryn formulates SLAs in terms of the computing resources (CPU, memory,
storage etc.) allocated to applications. It assumes a batch processing environment where the
execution time of an application is approximated based on a detailed description of the application provided
by the developer. In contrast, Cerebro handles SLAs for interactive web applications. It predicts
the response time of applications using static analysis, without any input from the application developer. 
Cerebro also supports automatic SLA renegotiation, with possible room for economic incentives.

Iosup et al showed via empirical analysis, that production cloud platforms like Google App Engine and AWS regularly
undergo performance variations, thus impacting the response time of the applications deployed in such
cloud platforms~\cite{5948601}. Some of these cloud platforms even exhibit temporal patterns 
in their performance variations (weekly, monthly, annual or seasonal). Cerebro and the associated API performance
forecasting model acknowledge this fact, and periodically re-evaluate the predicted response time upper bounds.
It detects when a previously predicted upper bound becomes invalid, and prompts the API clients to renegotiate their
SLAs accordingly. Indeed, one of Cerebro's strength's is its ability to detect change points in the input time series
data (periodically collected cloud SDK benchmark results), and generate up-to-date predictions that are not 
affected by old obsolete observations that were gathered prior to a change point.

There has also been prior work in the area of predicting 
SLA violations~\cite{Leitner10,6976585,Duan:2006:PIP:1142473.1142582}. 
These systems take an existing SLA and historical performance data of a service, and predict when the 
service might violate the given SLA in the future. 
%They employ some form of statistical analysis and/or machine learning to make such predictions. 
Cerebro's notion of SLA validity period has some relation to this line of research. However,
Cerebro's main goal is to make SLA predictions for web APIs \textit{before} 
they are deployed and executed. We believe that
some of these existing SLA violation predictors can complement our 
work by providing API developers and cloud
administrators insights on when a Cerebro-predicted SLA will be violated.
