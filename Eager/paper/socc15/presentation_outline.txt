================================

* Introduce self and collaborators
* Mention RaceLAB and UCSB
* Introduce high-level research area: Governance of web APIs for cloud platforms

================================

* Web services and SOA facilitate building complex distributed systems in a modular fashion
* Web APIs (network-enabled interfaces of web services):
   - make it easy to reuse existing services (and leverage other's development and maintenance efforts in the process)
* For these benefits, many developers expose their systems as APIs
* Consequently the Amount of web APIs available on the Internet has exploded over the last few years
   - ProgramableWeb stats from 2005 to 2013 indicate a near exponential growth
   - Latest API numbers are close to 14000

================================

* When considering the growth and the adoption of the API technology, we can see that APIs have become important resources, or "first-class citizens" 
  in the modern IT landscape. 
* It has come to the point that developers and users now reason about systems in terms of the APIs they consume and the APIs they expose.
* For example if you're developing a navigation application for a mobile device, you would most likely think about it in terms of an API like Google Maps. 
* Similarly, if you're the provider of an API like Google Maps, you would want to think about what your API should look like, and what other APIs you can use
  at the backend, in order to enhance your API by providing more data such as traffic information or nearby landmark information. 
* This transition of APIs into key IT resources poses several challenges as well.
   - APIs impact the correctness, performance and availability of applications
   - Most APIs do not provide strong guarantees with regard to such attributes thus compounding the issue
      > This makes it harder to use APIs in certain application domains (e.g. realtime or performance-critical apps)
   - Lack of tools to analyze and reason about API dependencies in an automated manner

================================

* Now what do all these entail? 
* A key implication of these problems is that the service-level agreements, or SLAs of applications are now closely tied to the SLAs of the APIs they consume.
* Plus, we need a mechanism to compose multiple API SLAs into a single application SLA
* This is really bad news for those who use cloud platforms to deploy APIs or those who wish to use APIs already deployed in the cloud.
   - Modern cloud platforms like Google or AWS as we know do not provide much in terms of an SLA
   - The best you can expect is an uptime SLA on an individual API (like the one shown here)
   - They do not provide performance SLAs, and they  most definitely do not provide performance SLAs regarding the user services or APIs deployed in the cloud

================================

* So given this limitation in the cloud platforms, we ask the question
   - Can we determine, automatically, performance SLAs for cloud-hosted applications and APIs?
   - If we can solve this problem, every API deployed into the cloud, will automatically get a performance SLA making them more dependable and easier to program with
* We took a stab at this problem, and came up with a system that we call Cerenro.
   - Predict the response time SLAs of web APIs using static analysis and statistical forecasting
   - Fully automatic
   - Designed to operate with PaaS clouds

================================

* Why did we focus on PaaS clouds?
   - PaaS clouds are extremely popular among developers as scalable, high available and cost effective deployment targets for web apps
      > Therefore a large amount of web apps today are deployed in PaaS environments (e.g. Snapchat, AppInventor etc)
   - PaaS clouds enforce restrictions on application code, thus making them amenable to static analysis
      > No arbitrary code or dependencies allows; Code must adhere to the provided cloud SDK
      > Restricted I/O (e.g. no file I/O on GAE)
      > Restricted threads (e.g. each thread must complete under 60s on GAE)

================================

* To further understand the domain of PaaS applications, we analyzed a collection of open source GAE apps available via Github
* 3 key observations
   - Not many branches
   - Not many loops
   - PaaS apps spend most of their time on executing cloud SDK calls
* This implies
   - PaaS applications are highly amenable to static analysis
   - Cloud SDK calls made by the app can give significant insights regarding the application performance

================================

* Cerebro architecture
   - Cloud SDK monitor runs in the cloud, periodically benchmarking cloud SDK operations, and recording the results as a set of time series (one series per operation)
   - When a developer submits a new web API to the cloud, Cerebro performs a static analysis on it to extract the sequence of cloud SDK calls made by it
   - In cases where there are cloud SDK calls within loops, we try to predict loop bounds (for data independent loops)
   - For data independent loops (common case in PaaS apps -- iterating a datastore result set), we prompt the developer to enter a suitable loop bound
   - The SLA predictor retrieves the time series data related to those cloud SDK calls, aggregates them, and uses QBETS to make an SLA prediction

================================

* QBETS simplified:
   - a non-parametric time series analysis and forecasting method that can predict instantaneous bounds on the percentiles of a time series
   - What does that mean? Suppose we are given a time series. If we treat it as a distribution of numbers, we can sort it and compute various percentiles on it
   - But these percentiles are instantaneous, in the sense they keep changing, as new data points are added to the time series
   - QBETS gives us the ability to predict upperbounds on the future values of the time series percentiles
   - And just like the percentiles we can compute off a given snapshot of a timeseries, these predictions are also instantaneous. 
   - We can and need to reevaluate them afer each data point addition

   - Another way to explain this is: Looks at the first n entries in a time series, and predicts an upper bound for the (n+1)th entry
   - We adapt QBETS to process time series data regarding cloud SDK performance and make SLA predictions for web APIs

   - Originally developed for predicting the queue delay bounds on batch computing systems
   - It also detects and deals with change points in the time series
   - Fast, efficient implementation available for online computation

================================

* Implemented prototype for GAE and AppScale
* Static analyzer - Soot; SDK monitor - GAE app; SLA predictor - Java, Go and QBETS (C)
* Tests carried out on GAE public cloud and AppScale private cloud (on a 4-node Euca cluster)
* Used a representative collection of open source Java GAE apps 
   - Covers branching, loops, single SDK call, multiple SDK calls etc

================================

Results - Prediction correctness
* We benchmark each app for 15-20hours (in 1 minute intervals)
* We also run the cloud SDK monitor in parallel on the same cloud
* We use Cerebro to make per-minute predictions for the whole time span of the experiment 
* Then we compare the actual app benchmark values againse Cerebro predictions

* For all cases Cerebro records an accuracy level close to higher than 95%
* In one case it's slightly below 95% (94.8), this is because QBETS accuracy fluctuations

================================

Results - Prediction tightness
* Desired accracy level can be achieved by simply making absurdly high predictions
* Challenge is to meet the desired accuracy goal, while making tight predictions (i.e. predict values close to the actual values)
* We compute the average difference between predicted and actual values
* In most cases Cerebro is no more than 65ms off
* When Cerebro predictions are way off, that is because the actual web API operation has highly variable performance traits
(getAllStudents operation on GAE)
* The mean of actual response times is around 3400ms, but the 95th percentile is over 4700ms
* That is the operation frequently registers very high response times
* To incorporate such high outliers, and meet the desired accuracy goals, Cerebro must predict a value that is far off from the mean
* That is Cerebro trades off tightness for accuracy

================================

In summary:
* As the API ecosystem continues to grow, we need APIs to give strong performance guarantees, and we need powerful tools to analyze and reason about them
* As a first step towards that goal we designed and implemented Cerebro, a system that predicts the response time SLAs for web APIs deployed in PaaS settings
* Cerebro uses a combination of static analysis and runtime monitoring of cloud SDK to predict API SLAs as they are deployed to the cloud
* Our empirical evaluation show that Cerebro is able to predict correct and tight performance SLAs for a wide range of PaaS-hosted applications and APIs

* In terms of ongoing and future work, we have been looking into the matter of SLA durability.
* In fact this paper also includes some preliminary results, but we have been conducting some long term experiments since then 
* Another related aspect we are interested in is SLA renegotiation
* We plan to intergrate Cerebro with EAGER for SLA-aware policy enforcement
* We plan to evaluate adaptive benchmarking strategies for the cloud SDK monitor (i.e. learn the operations and workloads to test from the deployed applications)

================================

Thanks and questions
