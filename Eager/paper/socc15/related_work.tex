Our research leverages a number of mature research areas in computer 
science and mathematics. These areas include static program analysis, 
cloud computing, time series analysis,
and SOA governance.

The problem of predicting execution time SLAs of web APIs 
is similar to worst-case execution
time (WCET) analysis~\cite{Wilhelm:2008:WEP:1347375.1347389,ermedahl2007loop,Sandberg:2006:FWF:1134650.1134666,Muchnick:1998:ACD:286076,Frost:2011:WAJ:2043910.2043916}. 
The objective of WCET analysis is to determine the maximum execution time of a software component in a given hardware platform. It is 
typically discussed in the context of real-time systems, where the developers should be able to document
and enforce precise hard real-time constraints on the execution time of programs. In order to save time, 
manpower and hardware resources, WCET analysis solutions are generally designed favoring static
analysis methods over software testing. We share similar concerns with regard to cloud platforms,
and strive to eliminate software testing in the favor of static analysis. 

Ermedahl et al designed and implemented SWEET~\cite{ermedahl2007loop}, a WCET analysis tool that make use of program slicing~\cite{Sandberg:2006:FWF:1134650.1134666},
 abstract interpretation~\cite{Cousot:1977:AIU:512950.512973} and invariant analysis~\cite{Muchnick:1998:ACD:286076} to determine the loop bounds and worst-case execution time 
 of a program. Program slicing helps to reduce the amount of code and program states that need to be 
 analyzed by SWEET. This is similar to our idea of extracting just the cloud SDK invocations form 
 a given web API code. SWEET uses abstract interpretation in interval and congruence domains to identify
 the set of values that can be assigned to key control variables of a program. These sets are then
 used to calculate exact loop bounds for most data-independent loops in the code. Invariant analysis  is
 used to detect variables that do not change during the course of a loop iteration, and remove them from
 the analysis thus further simplifying the loop bound estimation. Lokuceijewski et al propose 
 a similar WCET analysis using program slicing and abstract interpretation~\cite{Lokuciejewski:2009:FPS:1545006.1545064}. They additionally use a technique
called polytope models to speed up the analysis.  
%Frost et al have developed TetaJ, a WCET
 %tool for Java byte code programs~\cite{Frost:2011:WAJ:2043910.2043916}.
 
The corpus of research that covers the use of static analysis methods 
to estimate the execution time of software applications is 
extensive. Gulwani, Jain and Koskinen used two techniques named control-flow
 refinement and progress invariants to estimate the bounds for procedures with nested and multi-path loops~\cite{Gulwani:2009:CRP:1542476.1542518}.
 Gulwani, Mehra and Chilimbi proposed SPEED~\cite{Gulwani:2009:SPE:1480881.1480898}, a system that computes symbolic bounds for programs. This
 system makes use of user-defined quantitative functions to predict the bounds for loops iterating over
data structures like lists, trees and vectors. Our idea of using user-defined values to bound
 data-dependent loops (e.g. iterative datastore reads) is partly inspired by this concept.
 Bygde~\cite{bygde2010static} proposed a set of algorithms for predicting data-independent loops using abstract interpretation
 and element counting (a technique that was partly used in \cite{ermedahl2007loop}). 
Cerebro incorporates minor variations of these algorithms successfully due to their
simplicity.  
 
Cerebro makes use of and is similar to many of the execution time analysis 
systems discussed above.  However, there are also several key differences. 
For instance, Cerebro is focused on solving the
execution time prediction problem for PaaS-hosted web APIs. 
As we show in our characterization survey, such applications 
have a set of unique properties, that can be used to greatly simplify static analysis.
Also, Cerebro is designed to only work with web API codes. This makes designing 
a solution much more simpler but less general.
To handle the highly variable and evolving nature of
cloud platforms, Cerebro combines static analysis with runtime
monitoring of cloud platforms at the level of SDK operations. No other 
system provides such a hybrid approach to the best of our knowledge. 
Finally,
we use time series analysis~\cite{Nurmi:2007:QQB:1791551.1791556} 
to predict API execution time upper bounds with specific confidence
levels.

SLA management on service-oriented systems and cloud systems has also been 
throughly researched
over the years. However, a lot of the existing work has focused on issues 
such as SLA monitoring~\cite{Michlmayr:2009:CQM:1657755.1657756,Tripathy:2011:MMS:1980822.1980832,Raimondi:2008:EOM:1453101.1453125,Bertolino:2007:SUS:1294904.1294914}, SLA negotiation~\cite{Mahbub:2011:PSN:2061042.2062022,Yaqub:2014:ONS:2680847.2681496,6546098}, and SLA modeling~\cite{Chau:2008:ASM:1463788.1463802,Stamou:2013:SGM:2516588.2516592,Skene:2004:PSL:998675.999422}. 
Some work has also looked at incorporating a given SLA to the design of a system, and
then monitoring it at the runtime to ensure SLA compliant behavior~\cite{He:2013:TSC:2532443.2532449}. 
Our research takes a
different approach from such works, whereby it attempts to predict the performance SLAs for a
given web API implementation. To the best of our knowledge, Cerebro is the first system to predict performance SLAs for web APIs developed for PaaS clouds.

A work that is similar to ours has been proposed by Ardagna, Damiani and Sagbo in~\cite{6649675}. 
The authors develop
a system for early estimation of service performance based on simulations. Given a STS
model (Symbolic Transitions System) of a service, their system is able to generate a simulation script, which
can be used to assess the performance of the service. STS models are a type of finite state automata. 
Further, they use probabilistic distributions with fixed parameters
to represent the delays incurred by various operations in the service. Cerebro is easier to use than this
system because we do not require API developers to construct any models of the web APIs. 
%They only need to provide the source code of the API implementations. 
Also, instead of using probabilistic distributions
with fixed parameters, Cerebro uses actual historical performance metrics of cloud SDK operations. This enables
Cerebro to generate more accurate results, that reflect the dynamic nature of the cloud platform.

There has also been prior work in the area of predicting 
SLA violations~\cite{Leitner10,6976585,Duan:2006:PIP:1142473.1142582}. 
These systems take an existing SLA and historical performance data of a service, and predict when the 
service might violate the given SLA in the future. They employ some form of statistical analysis and/or machine learning to
make such predictions. Cerebro's notion of prediction validity period has some relation to this line of research. However,
Cerebro's main goal is to make SLA predictions for web APIs \textit{before} 
they are deployed and executed. We believe that
some of these existing SLA violation predictors can complement our 
work by providing API developers and cloud
administrators insights on when a Cerebro-predicted SLA will be violated.
