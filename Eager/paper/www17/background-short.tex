%\textcolor{blue}{You might want to move some of this discussion into the
%introduction since it allows the reader to understand the focus of the work we
%present.}
%Added more details about PaaS services to the intro

%\subsection{The PaaS Model} 

Our work concentrates on the web
applications deployed in PaaS clouds. An application of this nature exposes
one or more web application programming interfaces (web APIs) through which
clients can interact with it. The web APIs accept HTTP/S requests sent by
remote clients, and respond with machine readable responses (e.g. HTML, JSON,
XML, Protocol Buffers~\cite{protobuff}). This type of applications tend to be highly
interactive, and clients typically have strict expectations on the application
response time~\cite{latency-matters}. 
%Studies have shown that poor application response
%time may even lead to revenue loss~\cite{latency-matters}.
Additionally, the PaaS cloud on
which an application is running may impose additional constraints on the
application response time for scalability
reasons~\cite{azure-limits,gae-limits}.  For example Google App Engine
requires that no application request takes more than 60 seconds to execute.

PaaS-hosted web applications, like those that run on Google App Engine
(GAE)~\cite{gae},  
rely on various PaaS kernel services offered by the underlying
cloud platform. 
By offloading common application functionality such as data storage, caching,
user management, and security to a set of scalable and
managed cloud services, application developers
can greatly reduce the amount of code they have to write. 
%It also eliminates the need to install, run and
%manage many other support software that would otherwise be necessary (e.g. a database server, 
%a message broker etc.). 
In other words, when developing applications for a PaaS environment, the
developer simply focuses on implementing his/her application logic
using the available PaaS services to the greatest extent possible.
All the remaining deployment and utility services are left to be handled 
by the PaaS cloud. 

The downside of this approach is that application developers no longer have full runtime visibility
into the application execution. Since most of the application functionality is provided by a set 
of PaaS kernel services that are in cloud provider's domain, the application
developer does not have total control over application performance. If the application 
response time becomes too slow, the application developer is not in a position to determine
where in the entire cloud platform the performance bottleneck is due to the opacity of the cloud
platform's internal implementation. 

One way to circumvent this 
limitation is to instrument application code, and continuously monitor the time taken by various
parts of the application~\cite{newrelic,datadog,dynatrace}. 
But this activity can be tedious for the application developer, 
may be error prone thereby misleading those attempting to
diagnose a problem, and
the additional code instrumentation may slow down or alter the application's
performance. 
%Also there is no way to enforce correct, and consistent instrumentation of application code.  
%That is, the application developers must be careful in gathering and storing the appropriate
%runtime data. Otherwise their analyses will be inaccurate.
Implementing data collection and analysis as a service built into the PaaS cloud allows 
anomaly detection and bottleneck identification to be a ``curated'' service that is 
reliably managed by the cloud platform. The method of using low-level instrumentation
for root cause analysis has already proven effective in IaaS clouds~\cite{Dean:2014:PTR:2696535.2696551}.

\subsection{PaaS Performance Anomalies}

%In this work we define \textit{anomalies} as application performance change events that cause
%one or more performance SLOs to be violated. 

Our model is
one in which the clients of a web application have engaged in a
``service-level agreement'' (SLA)~\cite{Keller:2003:WFS:635430.635442}
with the ``owner'' or operator of the application that is hosted in a PaaS.  The SLA
stipulates a response-time ``service-level objective'' (SLO) that, if violated, constitutes a breech of the
agreement (similar to \cite{Nguyen:2011:PPR:2038633.2038634} but for PaaS).  A performance anomaly, then, is an event or set of events that
causes an application-level SLO to be violated.
%approach associates each application with
%a set of performance SLOs. We consider SLOs concerning the application response time
%(latency), which get violated when an application becomes too slow.
%If the performance of an application deteriorates to the
%point that at least one of its SLOs is violated, we treat it as an anomaly. 

Further, we refer to the process
of diagnosing whether increased workload or an unusually slow software component is responsible for
an anomaly, and in the latter case, the identification of the slow component
as \textit{root cause analysis}.  When request latency increases violating an SLO,
and the workload has not increased, we assume that there is a ``bottleneck''
component in the application code or PaaS runtime that is responsible.  Roots
performs root cause analysis in near real time so
that it can urgently alert cloud users and administrators of the detected problems.
%For a given anomaly, the root cause could be a change in the application workload or
%a \textit{bottleneck} in the application runtime.  Bottlenecks may occur in the application code, 
%or in the PaaS services that the application rely on.

%In order to maintain a satisfactory level of user experience and adhere to any previously
%agreed upon performance SLOs, application developers and cloud administrators wish
%to detect performance anomalies as soon as they occur. When detected, they
%must perform root cause analysis to identify the cause of the anomaly, and take some
%corrective and/or preventive action. 
%This diagnosis usually occurs as a two step process. First, one must determine
%whether the anomaly was caused by a change in the workload (e.g. a sudden 
%increase in the number of client requests). If that is the case,
%the resolution typically involves allocating more resources to the application or spawning
%more instances of the application for load balancing purposes. If the anomaly cannot be 
%attributed to a workload change, one must go another step to find the bottleneck component
%that has given rise to the issue at hand.

%Detecting performance anomalies
%requires continuous monitoring of application performance which could be tedious with
%cloud platforms in use today. It is even more challenging to perform root cause analysis
%due to the complexity and the blackbox nature of the cloud platforms. 

Note that there are several
third party cloud monitoring solutions available today which provide some performance
anomaly detection support~\cite{newrelic,datadog,dynatrace}. 
However, they require additional configuration, are expensive
and cannot support root cause analysis across the entire cloud stack since they do not
have visibility into all components of the cloud.
