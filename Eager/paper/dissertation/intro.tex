\textbf{Cloud computing turns compute infrastructures, programming platforms and software systems
into online utility services that can be easily shared among many users~\cite{hassan2011demystifying,Mell:2011:SND:2206223}.}
It enables processing and storing data on large, managed infrastructures and 
programming platforms, that can be accessed remotely via the internet. This provides an
alternative to running applications on local servers, personal computers, and mobile devices,
all of which have strict resource constraints. 

\textbf{Today, cloud computing technologies can be obtained from a large and growing number of providers.}
Some of these providers offer hosted cloud platforms that can be used
via the web to deploy applications without installing any physical hardware 
(e.g. Amazon AWS~\cite{amazon-aws-web}, Google App Engine~\cite{gae}, Microsoft Azure~\cite{azure-web}). Others
provide cloud technologies as downloadable software, which users can install
on their computers or data centers to set up their own private clouds 
(e.g. Eucalyptus~\cite{eucalyptus09}, AppScale~\cite{6488671}, OpenShift~\cite{openshift}).

\textbf{Cloud computing model provides high scalability, high availability and enhanced levels of 
user productivity.} Cloud platforms run on large resource pools, typically in one or more
data centers managed by the platform provider. Therefore cloud platforms have access to a vast
amount of hardware and software resources. This enables user applications
to scale to varying load conditions, and maintain high availability. Moreover, by offering resources
as utility services, cloud computing is able to facilitate a cost-effective, on-demand
resource provisioning model that greatly enhances user productivity. 

\textbf{Over the last decade cloud computing technologies have enjoyed explosive growth 
and near universal adoption due to their many benefits and 
promises~\cite{Antonopoulos:2010:CCP:1855007,Pinheiro:2014:ACC:2618168.2618188}.} 
Industry analysts project that the cloud computing market value will exceed \$150 billion
by the year 2020~\cite{cloud-growth}.
A large number of organizations
run their entire business as a cloud-based operation (e.g. Netflix, Snapchat). For startups
and academic researchers who do not have a large IT budget or a staff, the cost-effective 
on-demand resource provisioning model of the cloud has proved to be indispensable.
The growing number of academic conferences and journals dedicated to discussing
cloud computing is further evidence that cloud is an essential branch in the field
of computer science.

\textbf{Despite its many benefits, cloud computing has also given rise to several application
development and maintenance challenges that have gone unaddressed for many years.}
As the number of applications deployed in cloud platforms continue to increase these
shortcoming are rapidly becoming conspicuous. We highlight three such issues.
 
\textbf{First and foremost, cloud platforms lack the ability to enforce developer best practices
and administrative conformance on deployed user applications.} The developer best practices 
are the result of decades of software engineering research, and
include code reuse, proper versioning of software artifacts, dependency management
between application components, and backward compatible software updates. Administrative
conformance refers to complying with various development and maintenance standards
that an organization may wish to impose on all of their production software.
Cloud platforms do not provide any facilities that enforce such developer practices or
administrative standards. Instead, cloud platforms
make it extremely trivial and quick to deploy new applications or update existing
applications (i.e. roll out new versions). The resulting speed-up of the development cycles combined with the lack of 
oversight and verification, makes it extremely difficult for 
IT personnel to manage large volumes of cloud-hosted applications.

\textbf{Secondly, today's cloud platforms do not provide any support for reasoning about the 
performance of the deployed applications.} When an application is implemented for
a given cloud platform, one must subject it to extensive performance testing in order
to comprehend its performance limits; a process that is both 
tedious and time consuming. The difficulty in understanding the performance 
traits of cloud-hosted applications is primarily due to the very high level of 
abstraction provided by the cloud platforms. These abstractions shield many details 
concerning the application runtime, and without visibility into such low level application 
execution details it is impossible
to build a robust performance model for a cloud-hosted application. Due to the same
reason, it is also not possible to stipulate bounds (service level objectives or SLOs) on
the performance of cloud-hosted applications. 
Consequently, existing cloud platforms only offer such guarantees regarding service availability.
However, strong statistical bounds on application performance are vital for developers 
who implement downstream systems that consume the cloud-hosted applications,
and cloud administrators who wish to maintain a consistent quality of service
level.

\textbf{Thirdly, cloud platforms do not provide adequate support for performance debugging
user applications.} Most cloud platforms only provide the simplest monitoring and logging features,
and do not provide any mechanisms for detecting performance anomalies or identifying
bottlenecks in the application code or the underlying cloud platform. This limitation has given rise
to a new class of third party service providers that specialize in monitoring cloud applications
(e.g. New Relic~\cite{newrelic}, Dynatrace~\cite{dynatrace}, Datadog~\cite{datadog}). But these 
third party solutions are expensive, and they require additional configuration. 
They also mandate instrumentation of application code, which if not done
correctly, may lead to incorrect diagnoses concerning application performance. The cloud
platforms do not provide any facilities for ensuring correct instrumentation, and the perturbation
introduced by the instrumentation is also likely to change and degrade the application performance.
Furthermore, the extrinsic, third party monitoring systems only have a restricted view 
of the user application, due to the high level of abstraction provided by cloud platform software.
This limits the capabilities of the monitoring systems in terms of the type of analyses they can carry out.
Today's cloud platforms are also very large and complex with many interacting components.
An external monitoring service cannot observe this complexity in full, and hence cannot pinpoint
the component that might be responsible for a perceived application performance anomaly.

\textbf{In order to make the cloud computing model more dependable and convenient for the users as well
as the cloud service providers, the above limitations need to be addressed satisfactorily.}
Doing so will also greatly simplify the tasks of developing cloud applications, and maintaining 
them in the long run. Developers will be able to specify SLOs on the performance of
their cloud-hosted applications, and offer competitive service level agreements (SLAs) to the end users that consume those
applications. Developers as well as cloud administrators will be able to detect performance anomalies
promptly, and take corrective actions before the issues escalate to major
outages or other crises. Therefore, as a means of reaching this goal, we propose and explore the
following thesis question.

{\bf Can we efficiently enforce governance on cloud-based web applications to achieve 
administrative conformance, developer best practices, and performance objectives through 
automated analysis and diagnostics?} 

\textbf{We define governance in this context as the mechanism by which the acceptable 
operational parameters are specified and maintained in a software system.} This involves 
multiple steps:
\begin{itemize}
\item Specifying the acceptable operational parameters
\item Enforcing the specified parameters
\item Monitoring the system to detect deviations from the acceptable behavior
\item Taking preventive or corrective action when necessary
\end{itemize}

\textbf{The concept of software system governance as defined here is analogous to the
notion of governing a country.} In a country too we should specify the acceptable
parameters, which establishes the general laws and the rights of the citizens. Such 
parameters are then
enforced by various authorities. When some person or a group deviates from those parameters,
it is detected, and corrective action is taken by bringing the responsible party to the justice.

Automated governance protocols have been designed and implemented for software systems in
the past, specially in classic web services and service-oriented architecture (SOA) applications. 
Such systems enable specifying
acceptable behavior via machine readable policies, which are then automatically enforced by
a policy enforcement agent. Monitoring agents watch the system to detect any deviations from
the acceptable behavior (i.e. policy violations), and alert users or follow predefined corrective
procedures. \textbf{We can envision facilities similar to SOA governance being implemented in a cloud platform to 
enforce good programming practices and various performance objectives.} The operational
parameters in this case may include coding and packaging conventions for the cloud-hosted
applications, and their expected level of performance.

\textbf{In order for governance to be
useful within the scope of cloud computing, it must be both efficient and automated.}
Cloud platforms are comprised of many components that need to be managed with
separate policies. 
They also serve a very large number of users who deploy applications in
the cloud. Therefore governance systems designed for the cloud should scale to handle a 
large volume of applications and policies,
without introducing a significant runtime overhead to the cloud-hosted applications.
Also they must be fully automated since it is not practical for a human administrator to be
involved in the governance process given the scale of the cloud platforms.

\textbf{In order to answer the above thesis question by developing efficient, automated governance systems,
we take the following three-step approach.}
\begin{itemize}
\item Design and implement a scalable, low-overhead governance framework for cloud platforms,
complete with a policy specification language and a policy engine. The governance framework should be
built into the cloud platforms, and must
keep the runtime overhead of the user applications to a minimum while enforcing
common developer best practices and other organizational conventions.
\item Design and implement a methodology for formulating statistical bounds (SLOs) on the
performance of cloud-hosted web applications, without
 subjecting them to extensive performance testing or instrumentation. The formulated
bounds must be correct, tight and durable in the face of changing
 conditions of the cloud.
 \item Design and implement a scalable cloud application monitoring framework for detecting
performance anomalies and diagnosing potential root causes. 
The framework should support collecting
 a wide range of runtime data from the user applications and the underlying cloud platform
 without instrumenting the user code, and without introducing significant runtime overheads.
 It should further facilitate employing a number of new and existing statistical methods,
 and algorithms to analyze the gathered data.
\end{itemize}

\textbf{To minimize the impact of policy enforcement on application performance,
we divide the application life cycle into multiple phases, and perform policy
enforcement tasks when the application is being deployed; a technique that we
refer to as deployment-time policy enforcement.} 
We explore the
trade off between what policies can be enforced, and when they can be enforced with respect
to the life cycle of a cloud-hosted application. 
We show that not all policies
are enforceable at deployment-time, and therefore some support for run-time policy enforcement
is also required in the cloud. However, we find that
deployment-time policy enforcement is efficient, and a governance framework that
performs most, if not all, enforcement tasks at deployment-time can scale
to thousands of applications and policies.

\textbf{To formulate performance bounds for cloud-hosted applications without subjecting them to extensive testing,
we need mechanisms that can identify the key operations executed by an application, and a
statistical framework to reason about the performance of those operations.} We use static
analysis to extract the sequence of critical operations (cloud services) invoked by a given application.
We continuously monitor the cloud platform to construct a historic performance model of the individual operations.
We employ a time series analysis and forecasting method to combine static analysis results with
platform monitoring data to
derive statistical guarantees on the application response time. These calculated performance
bounds are associated with a specific correctness probability, and hence are suitable to be used
as SLOs. We demonstrate that the bounds formulated via this approach are 
both accurate, and closely resemble the actual performance of the applications. We also present a statistical framework
to reason about the validity period of each bound, and show that the predicted bounds
remain correct for periods ranging from several hours to several weeks.

\textbf{In order to facilitate performance anomaly detection and root cause analysis without instrumenting
application code, we need to capture various performance events that occur in the cloud platform,
correlate them, and employ statistical analysis to identify anomalous patterns in them.} Any given statistical
method is only sensitive to a certain class of anomalies. Therefore, to be able to diagnose a wide range of
performance anomalies, we should devise algorithms that combine multiple statistical analysis
methods. We propose a performance diagnosis methodology that combines linear regression, change point
detection and quantile analysis. Our approach detects performance anomalies in near real time,
and identifies the root cause of each anomaly as a workload change or a performance bottleneck
in the cloud platform. In case of performance bottlenecks, our approach can also correctly identify
the exact component in the cloud platform, in which the bottleneck manifested.

\textbf{Our contributions push the state of the art in cloud computing significantly towards achieving
administrative conformance, developer best practices and performance objectives.} Moreover,
our work addresses three out of the four steps associated with software system governance --
specification, enforcement and monitoring. We show that these alone can significantly improve cloud platforms
in terms of their reliability, developer-friendliness and ease of management. 
We do not directly tackle remediation, but our work
lays the groundwork for implementing automated problem remediation in future cloud platforms.