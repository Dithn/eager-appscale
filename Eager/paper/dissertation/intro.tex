Cloud computing turns compute infrastructures, programming platforms and software systems
into online utility services that can be easily shared among many users~\cite{hassan2011demystifying,Mell:2011:SND:2206223}.
It enables processing and storing data on large, managed infrastructures and 
programming platforms, that can be accessed remotely via the internet. This provides an
alternative to running applications on local servers, personal computers, and mobile devices,
all of which have strict resource constraints. 
Today, cloud computing technologies can be obtained from a large and growing number of providers.
Some of these providers offer hosted cloud platforms that can be used
via the web to deploy applications without installing any physical hardware 
(e.g. Amazon AWS~\cite{amazon-aws-web}, Google App Engine~\cite{gae}, Microsoft Azure~\cite{azure-web}). Others
provide cloud technologies as downloadable software, which users can install
on their computers or data centers to set up their own private clouds 
(e.g. Eucalyptus~\cite{eucalyptus09}, AppScale~\cite{6488671}, OpenShift~\cite{openshift}).

Cloud computing model provides high scalability, high availability and enhanced levels of 
user productivity. Cloud platforms run on large resource pools, typically in one or more
data centers managed by the platform provider. Therefore cloud platforms have access to a vast
amount of hardware and software resources. This enables cloud-hosted applications
to scale to varying load conditions, and maintain high availability. Moreover, by offering resources
as utility services, cloud computing is able to facilitate a cost-effective, on-demand
resource provisioning model that greatly enhances user productivity. 

Over the last decade cloud computing technologies have enjoyed explosive growth, 
and near universal adoption due to their many benefits and 
promises~\cite{Antonopoulos:2010:CCP:1855007,Pinheiro:2014:ACC:2618168.2618188}.
Industry analysts project that the cloud computing market value will exceed \$150 billion
by the year 2020~\cite{cloud-growth}.
A large number of organizations
run their entire business as a cloud-based operation (e.g. Netflix, Snapchat). For startups
and academic researchers who do not have a large IT budget or a staff, the cost-effective 
on-demand resource provisioning model of the cloud has proved to be indispensable.
The growing number of academic conferences and journals dedicated to discussing
cloud computing is further evidence that cloud is an essential branch in the field
of computer science.

Despite its many benefits, cloud computing has also given rise to several application
development and maintenance challenges that have gone unaddressed for many years.
As the number of applications deployed in cloud platforms continue to increase these
shortcoming are rapidly becoming conspicuous. We highlight three such issues.
 
Firstly, cloud platforms lack the ability to enforce developer best practices
and administrative conformance on deployed user applications. The developer best practices 
are the result of decades of software engineering research, and
include code reuse, proper versioning of software artifacts, dependency management
between application components, and backward compatible software updates. Administrative
conformance refers to complying with various development and maintenance standards
that an organization may wish to impose on all of their production software.
Cloud platforms do not provide any facilities that enforce such developer practices or
administrative standards. Instead, cloud platforms
make it extremely trivial and quick to deploy new applications or update existing
applications (i.e. roll out new versions). The resulting speed-up of the development cycles combined with the lack of 
oversight and verification, makes it extremely difficult for 
IT personnel to manage large volumes of cloud-hosted applications.

Secondly, today's cloud platforms do not provide support for establishing 
service level objectives (SLOs) regarding the performance of deployed applications.
A performance SLO specifies a bound on application's response time (latency). 
Such bounds are vital for developers 
who implement downstream systems that consume the cloud-hosted applications,
and cloud administrators who wish to maintain a consistent quality of service
level. However, when an application is implemented for
a cloud platform, one must subject it to extensive performance testing in order
to comprehend its performance bounds; a process that is both 
tedious and time consuming. The difficulty in understanding the performance 
bounds of cloud-hosted applications is primarily due to the very high level of 
abstraction provided by the cloud platforms. These abstractions shield many details 
concerning the application runtime, and without visibility into such low level application 
execution details it is impossible
to build a robust performance model for a cloud-hosted application. Due to this
reason, it is not possible to stipulate SLOs on the performance of cloud-hosted applications. 
Consequently, existing cloud platforms only offer SLOs regarding service availability.

Thirdly, cloud platforms do not provide adequate support for monitoring application performance,
and running diagnostics when an application fails to meet its performance SLOs.
Most cloud platforms only provide the simplest monitoring and logging features,
and do not provide any mechanisms for detecting performance anomalies or identifying
bottlenecks in the application code or the underlying cloud platform. This limitation has given rise
to a new class of third party service providers that specialize in monitoring cloud applications
(e.g. New Relic~\cite{newrelic}, Dynatrace~\cite{dynatrace}, Datadog~\cite{datadog}). But these 
third party solutions are expensive. They also require code instrumentation, which
if not done correctly, leads to incorrect diagnoses. The perturbation
introduced by the instrumentation also changes and degrades application performance.
Furthermore, the extrinsic monitoring systems have a restricted view 
of the cloud platform, due to the high level of abstraction provided by cloud platform software.
Therefore they cannot observe the complexity of the cloud platform in full, and hence cannot pinpoint
the component that might be responsible for a perceived application performance anomaly.

In order to make the cloud computing model more dependable, maintainable and convenient for the users as well
as the cloud service providers, the above limitations need to be addressed satisfactorily.
Doing so will greatly simplify the tasks of developing cloud applications, and maintaining 
them in the long run. Developers will be able to specify SLOs on the performance of
their cloud-hosted applications, and offer competitive service level agreements (SLAs) to the end users that consume those
applications. Developers as well as cloud administrators will be able to detect performance anomalies
promptly, and take corrective actions before the issues escalate to major
outages or other crises.

Our research focuses on addressing the above issues in cloud environments 
using \textit{governance}. We define governance as the mechanism 
by which the acceptable operational parameters are specified and maintained in a 
software system~\cite{brown2005framing,gartner-soa-gov}. This involves multiple steps:
\begin{itemize}
\item Specifying the acceptable operational parameters
\item Enforcing the specified parameters
\item Monitoring the system to detect deviations from the acceptable behavior
\end{itemize}

To learn the feasibility and the efficacy of applying governance
techniques in a cloud platform, we propose and explore the following thesis
question:
Can we efficiently enforce governance for cloud-hosted web applications to achieve 
administrative conformance, developer best practices, and performance SLOs through 
automated analysis and diagnostics?

For governance to be
useful within the context of cloud computing, it must be both efficient and automated.
Cloud platforms are comprised of many components that have different life cycles
and maintenance requirements. 
They also serve a very large number of users who deploy applications in
the cloud. Therefore governance systems designed for the cloud should scale to handle a 
large number of applications and related software components,
without introducing a significant runtime overhead on them.
Also they must be fully automated since it is not practical for a human administrator to be
involved in the governance process given the scale of the cloud platforms.

Automated governance for software systems is a well researched area,
especially in connection with classic web services and service-oriented architecture 
(SOA) applications~\cite{gartner-soa-gov,soagov,Schepers:2008:LAS:1363686.1363932,5577268,4730489}. 
We adapt the methodologies outlined in the existing SOA governance research corpus, so
they can be applied to cloud computing systems.
These methodologies enable specifying
acceptable behavior via machine readable policies, which are then automatically enforced by
a policy enforcement agent. Monitoring agents watch the system to detect any deviations from
the acceptable behavior (i.e. policy violations), and alert users or follow predefined corrective
procedures. We can envision similar facilities being implemented in a cloud platform to 
achieve administrative conformance, developer best practices and performance SLOs. The operational
parameters in this case may include coding and deployment conventions for the cloud-hosted
applications, and their expected performance levels.

In order to answer the above thesis question by developing efficient, automated governance systems,
we take the following three-step approach.
\begin{itemize}
\item Design and implement a scalable, low-overhead governance framework for cloud platforms,
complete with a policy specification language and a policy enforcer. The governance framework should be
built into the cloud platforms, and must
keep the runtime overhead of the user applications to a minimum while enforcing
developer best practices and administrative conformance.
\item Design and implement a methodology for formulating performance SLOs (bounds)
for cloud-hosted web applications, without
 subjecting them to extensive performance testing or instrumentation. The formulated
SLOs must be correct, tight and durable in the face of changing conditions of the cloud.
 \item Design and implement a scalable cloud application performance monitoring (APM) framework for detecting
violations of performance SLOs. For each
violation detected, the framework should be able to run diagnostics, and identify the potential
root cause. It should support collecting data from the cloud platform
 without instrumenting user code, and without introducing significant runtime overheads.
\end{itemize}

To achieve administrative conformance and developer best practices with minimal overhead,
we perform governance policy enforcement when an application is deployed; a technique that we
term deployment-time policy enforcement.
We explore the
trade off between what policies can be enforced, and when they can be enforced with respect
to the life cycle of a cloud-hosted application. We show that not all policies
are enforceable at deployment-time, and therefore some support for run-time policy enforcement
is also required in the cloud. However, we find that
deployment-time policy enforcement is efficient, and a governance framework that
performs most, if not all, enforcement tasks at deployment-time can scale
to thousands of applications and policies.

We combine static analysis with platform monitoring to establish performance SLOs for
cloud-hosted applications. Static analysis
extracts the sequence of critical operations (cloud services) invoked by a given application.
Platform monitoring facilitates constructing a historic performance model for the individual operations.
We then employ a time series analysis method to combine these results, and calculate statistical bounds 
for application response time. The performance bounds calculated in this manner
are associated with a specific correctness probability, and hence can be used
as SLOs. We also devise a statistical framework to evaluate the validity period of 
calculated performance bounds.

In order to detect and diagnose performance SLO violations,
we monitor various performance events that occur in the cloud platform,
correlate them, and employ statistical analysis to identify anomalous patterns. Any given statistical
method is only sensitive to a certain class of anomalies. Therefore, to be able to diagnose a wide range of
performance anomalies, we devise an algorithm that combines linear regression, change point
detection and quantile analysis. Our approach detects performance SLO violations in near real time,
and identifies the root cause of each event as a workload change or a performance bottleneck
in the cloud platform. In case of performance bottlenecks, our approach also correctly identifies
the exact component in the cloud platform, in which the bottleneck manifested.

Our contributions push the state of the art in cloud computing significantly towards achieving
administrative conformance, developer best practices and performance SLOs. Moreover,
our work addresses all the major steps associated with software system governance --
specification, enforcement and monitoring. We show that this approach can significantly improve cloud platforms
in terms of their reliability, developer-friendliness and ease of management. We also demonstrate
that the governance capabilities proposed in our work can be built into existing cloud platforms,
without having to implement them from the scratch.