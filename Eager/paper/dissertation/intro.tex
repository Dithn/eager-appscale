Cloud computing has revolutionized the way programmers develop and deploy applications.
\textbf{Cloud computing turns compute infrastructures, programming platforms and software systems
into online utility services that can be easily shared with many users~\cite{hassan2011demystifying,Mell:2011:SND:2206223}.}
By running computations and storing data on large, managed infrastructures and 
programming platforms, cloud computing ensures scalability and high-availability of 
user applications. Moreover, by offering such resources
as utility services, cloud computing is able to facilitate a cost-effective, on-demand
resource provisioning model that greatly enhances user productivity.

\textbf{Over the last decade cloud computing technologies have enjoyed explosive growth 
and near universal adoption due to their many benefits and 
promises~\cite{Antonopoulos:2010:CCP:1855007,Pinheiro:2014:ACC:2618168.2618188}.} 
Industry analysts project that the cloud computing market value will exceed \$150 billion
by the year 2020~\cite{cloud-growth}.
Already core cloud 
functionalities are available from a large and growing number of service providers. 
Some of these service providers offer hosted cloud solutions that can be used
via the web to deploy applications without installing any physical hardware 
(e.g. Amazon AWS~\cite{amazon-aws-web}, Google App Engine~\cite{gae}, Microsoft Azure~\cite{azure-web}). Others
provide cloud technologies as downloadable software, which users can install
on their computers or data centers to set up their own private clouds 
(e.g. Eucalyptus~\cite{eucalyptus09}, AppScale~\cite{6488671}, OpenShift~\cite{openshift}). 

\textbf{Both the IT industry and the academia have responded very positively to this new 
model of application 
development.} Many business organizations are currently in the process of migrating
their IT infrastructure to the cloud. A large number of organizations
run their entire business as a cloud-based operation (e.g. Netflix, Snapchat). For startups
and academic researchers who do not have a large IT budget or a staff, the cost-effective 
on-demand resource provisioning model of the cloud has proved to be indispensable.
The growing number of academic conferences and journals dedicated to discussing
cloud computing is further evidence that cloud is an essential branch in the field
of computer science.

\textbf{Despite its many benefits, cloud computing has also given rise to several application
development and maintenance challenges that have gone unaddressed for many years.}
As the number of applications deployed in cloud platforms continue to increase these
shortcoming are rapidly becoming conspicuous. We highlight three such issues.
 
\textbf{First and foremost, cloud platforms do not enforce any of the developer best practices
the software engineering community has established over the last half-century.} This
includes code reuse, proper versioning of software artifacts, dependency management
between application components and backward compatible code updates. In
some cases, organizations require certain development and maintenance standards to be enforced on
all production software. Cloud platforms do not provide any facilities for attaining
such administrative conformance on cloud-hosted applications. Instead, cloud platforms
make it extremely trivial and quick to deploy new applications or update existing
applications (i.e. roll out new versions). The resulting speed-up of the development cycles combined with the lack of 
oversight and verification, makes it extremely difficult for 
IT personnel to manage large volumes of cloud-hosted applications.

\textbf{Secondly, today's cloud platforms do not provide any support for reasoning about the 
performance of the deployed applications.} When an application is implemented for
a given cloud platform, one must subject it to extensive performance testing in order
to comprehend its performance limits; a process that is both 
tedious and time consuming. The difficulty in understanding the performance 
traits of cloud-hosted applications is primarily due to the very high level of 
abstraction provided by the cloud platforms. These abstractions shield many details 
concerning the application runtime, and without visibility into such low level application 
execution details it is impossible
to build a robust performance model for a cloud-hosted application. Due to the same
reason, it is also not possible to stipulate upper bounds (service level objectives or SLOs) on
the performance of cloud-hosted applications. 
Consequently, existing cloud platforms only offer such guarantees regarding service availability.
However, strong statistical upper bounds on application performance are vital for developers 
who implement downstream systems that consume the cloud-hosted applications,
and cloud administrators who wish to maintain a consistent quality of service
level.

\textbf{Thirdly, cloud platforms provide very poor support for performance debugging
user applications.} Most cloud platforms only provide the simplest monitoring and logging features,
and do not provide any mechanisms for detecting performance anomalies or identifying
bottlenecks in the application code or the underlying cloud platform. This limitation has given rise
to a new class of third party service providers that specialize in monitoring cloud applications
(e.g. New Relic~\cite{newrelic}, Dynatrace~\cite{dynatrace}, Datadog~\cite{datadog}). But these 
third party solutions are expensive, and they require additional configuration. 
They also mandate instrumentation of application code, which if not done
correctly, may lead to incorrect diagnoses concerning application performance. The cloud
platforms do not provide any facilities for ensuring correct instrumentation, and the perturbation
introduced by the instrumentation is also likely to change and degrade the application performance.
Furthermore, the extrinsic, third party monitoring systems only have a restricted view 
of the user application, due to the high level of abstraction provided by cloud platform software.
This limits the capabilities of the monitoring systems in terms of the type of analyses they can carry out.
Today's cloud platforms are also very large and complex with many interacting components.
An external monitoring service cannot observe this complexity in full, and hence cannot pinpoint
the component that might be responsible for a perceived application performance anomaly.

\textbf{In order to make cloud computing more reliable and dependable for the users as well
as the cloud service providers, the above limitations need to be addressed satisfactorily.}
Doing so will also greatly simplify the tasks of developing cloud applications, and maintaining 
them in the long run. Developers will be able to specify SLOs on the performance of
their cloud-hosted applications, and offer competitive service level agreements (SLAs) to the end users that consume those
applications. Developers as well as cloud administrators will be able to detect performance anomalies
promptly, and take corrective actions before the issues escalate to major
outages or other crises. Therefore, as a means of reaching this goal, we propose and explore the
following thesis question.

{\bf Can we efficiently enforce governance on cloud-based web applications to achieve 
administrative conformance, developer best practices, and performance objectives through 
automated analysis and diagnostics?} 

\textbf{Governance in this context can be defined as the mechanism by which the acceptable 
operational parameters are specified and maintained in a software system.} This involves 
multiple steps:
\begin{itemize}
\item Specifying the acceptable operational parameters
\item Enforcing the specified parameters
\item Monitoring the system to detect deviations from the acceptable behavior
\item Taking preventive or corrective action when necessary
\end{itemize}

\textbf{The concept of software system governance as defined here is analogous to the
notion of governing a country.} In a country too we should specify the acceptable
parameters, which establishes the general laws and the rights of the citizens. Such 
parameters are then
enforced by various authorities. When some person or a group deviates from those parameters,
it is detected, and corrective action is taken by bringing the responsible party to the justice.

Automated governance protocols have been designed and implemented for software systems in
the past, specially in classic web services and service-oriented architecture (SOA) applications. 
Such systems enable specifying
acceptable behavior via machine readable policies, which are then automatically enforced by
a policy enforcement agent. Monitoring agents watch the system to detect any deviations from
the acceptable behavior (i.e. policy violations), and alert users or follow predefined corrective
procedures. \textbf{We can envision facilities similar to SOA governance being implemented in a cloud platform to 
enforce good programming practices and various performance objectives.} The operational
parameters in this case may include coding and packaging conventions for the cloud-hosted
applications, and their expected level of performance.

\textbf{In order for governance to be
useful within the scope of the cloud, we must be able to meet two additional
goals -- efficiency and automation.} First, the governance should be 
efficient in the sense that it should not introduce
a significant runtime overhead to the cloud-hosted applications, and it should scale up to
handle a large number of applications and policies. Secondly, the governance should be
fully automated. Since cloud platforms are comprised of thousands of applications and components,
it is not practical for a human administrator to be involved in the governance process.

Extending on the above thesis question, and the vision for efficient, automated governance for
cloud-hosted applications, we devise the following research plan:

\begin{itemize}
\item Design and implement a scalable, low-overhead governance framework for cloud platforms,
complete with a policy specification language and a policy engine. The governance framework should be
built into the cloud platforms, and must
keep the runtime overhead of the user applications to a minimum while enforcing
common developer best practices and other organizational conventions.
\item Design and implement a methodology for formulating statistical upper bounds on the
performance of cloud-hosted web applications, without
 subjecting them to extensive performance testing or instrumentation. The formulated
upper bounds must be correct, tight and durable in the face of changing
 conditions of the cloud.
 \item Design and implement a scalable cloud application monitoring framework for detecting
performance anomalies and diagnosing potential root causes. 
The framework should support collecting
 a wide range of runtime data from the user applications and the underlying cloud platform
 without instrumenting the user code, and without introducing significant runtime overheads.
 It should further facilitate employing a number of new and existing statistical methods,
 and algorithms to analyze the gathered data.
\end{itemize}

We need to address a number of scientific questions in order to successfully execute the 
above research plan. First we must a devise a methodology to enforce policies efficiently
without introducing a significant overhead to application performance. There is an interesting
trade off to be explored here between what policies can be enforced, and when they can be enforced with respect
to the life cycle of a cloud-hosted application. We solve these problems by dividing the application
life cycle into three phases -- development-time, deployment-time and run-time. \textbf{To minimize the
impact of policy enforcement on application performance, we perform most policy
enforcement tasks during deployment-time; i.e. when an application is being deployed in the 
cloud platform, before it is executed.} However, we acknowledge that not all policies
are enforceable at deployment-time, and therefore some support for run-time policy enforcement
is also required. We design our policy enforcement framework based on these principles, and 
show that deployment-time policy enforcement is efficient, and such an implementation can scale
to thousands of applications and policies.

To formulate performance upper bounds for cloud-hosted applications without subjecting them to extensive testing,
we need mechanisms that can identify the key operations executed by an application, and a
statistical framework to reason about the performance of those operations. We use static
analysis to extract the sequence of critical operations (cloud services) invoked by a given application.
We continuously monitor the cloud platform to construct a historic performance model of the individual operations.
\textbf{We employ a time series analysis and forecasting method to combine static analysis results with
platform monitoring data to
derive statistical guarantees on the application response time.} These calculated performance
upper bounds are associated with a specific correctness probability, and hence are suitable to be used
as SLOs. We demonstrate that the upper bounds formulated via this approach are 
both accurate, and closely resemble the actual performance of the applications. We also present a statistical framework
to reason about the validity period of each upper bound, and show that the predicted bounds
remain correct for periods ranging from several hours to several weeks.

In order to facilitate performance anomaly detection and root cause analysis without instrumenting
application code, we need to capture various performance events that occur in the cloud platform
when an application responds to a user request. We should then correlate these different events,
and employ statistical analysis to identify anomalous behaviors in them. Any given statistical
method is only sensitive to a certain class of anomalies. Therefore, to be able to diagnose a wide range of
performance anomalies, we should devise algorithms that combine multiple statistical analysis
methods. \textbf{We propose a performance diagnosis methodology that combines linear regression, change point
detection and quantile analysis.} Our approach detects performance anomalies in near real time,
and identifies the root cause of each anomaly as a workload change or a performance bottleneck
in the cloud platform. In case of performance bottlenecks, our approach can also correctly identify
the exact component in the cloud platform, in which the bottleneck manifested.

\textbf{While not an exhaustive approach for implementing governance in the cloud, our research plan
pushes the state of the art in cloud computing significantly towards achieving
administrative conformance, developer best practices and performance objectives.} Moreover,
our work addresses three out of the four steps associated with software system governance --
specification, enforcement and monitoring. We show that these alone can significantly improve cloud platforms
in terms of their reliability, developer-friendliness and ease of management. 
We do not directly tackle remediation, but our work
lays the groundwork for implementing automated problem remediation in future cloud platforms.

Following chapter provides the background details regarding cloud computing and governance.
Next three chapters further elaborate on the above three objectives respectively. 
Each chapter details our designs, assumptions and related work. Implementation details,
results and future work are also discussed where appropriate. Final chapter
summarizes and concludes this dissertation.