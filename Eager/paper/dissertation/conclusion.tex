Cloud computing delivers IT infrastructure resources, programming platforms, and software
applications as shared utility services. Enterprises and developers increasingly deploy applications 
on cloud platforms due to their scalability, high availability and many other
productivity enhancing features. Cloud-hosted applications depend on the core services provided
by the cloud platform for compute, storage and network resources. 
In some cases they use the services provided by the cloud to implement most of
the application functionality as well (e.g. PaaS-hosted applications). 
Cloud-hosted applications are typically
accessed over the Internet, via the web APIs exposed by the applications.

As the applications hosted in cloud platforms continue to increase in number, the need for enforcing
governance on them becomes accentuated. We define governance as the mechanism by which the 
acceptable operational parameters are specified and maintained for a cloud-hosted application.
Governance enables specifying the acceptable
development standards and runtime parameters (performance, availability, security requirements etc.) 
for cloud-hosted applications as policies. Such
policies can then be enforced automatically at various stages of the application life-cycle. 
Governance further entails
monitoring cloud-hosted applications to ensure that they operate at a certain level of quality,
and taking corrective action when deviations are detected. Through the steps of specification,
enforcement, monitoring and correction, governance can help resolve a number of prevalent issues in
today's cloud platforms. These issues include lack of good software engineering practices (code reuse,
dependency management, versioning etc), lack of performance SLOs for cloud-hosted applications,
and lack of performance debugging support. 

We explore the feasibility of efficiently enforcing governance on cloud-hosted
applications, and evaluate the effectiveness of governance as a means of achieving administrative
conformance, developer best practices and performance objectives in the cloud. Considering the scale of
today's cloud platforms in terms of the number of users and the applications, 
we strive to automate much of the governance tasks through
automated analysis and diagnostics. To achieve efficiency, we put more emphasis on deployment-time
policy enforcement, static analysis of performance limits, and non-invasive passive monitoring of 
cloud platforms, thereby keeping the governance overhead
to a minimum. We avoid run-time enforcement and invasive instrumentation of cloud applications 
as much as possible. We also focus on building governance systems that are deeply integrated with
the cloud platforms themselves. This enables using the existing scalability and high availability features of the cloud
to provide an efficient governance solution that can control all application events in a fine-grained
manner. Furthermore, such integrated solutions relieve the users from having to maintain and pay
for additional, external governance and monitoring solutions.

With the goal of efficient, integrated and automated governance for cloud-hosted applications in mind,
we propose the following three research goals.
\begin{enumerate}
\item Design and implement a scalable, low-overhead governance framework for cloud platforms,
complete with a policy specification language and a policy engine. The governance framework should be
integrated into the cloud platforms, and must
strive to keep the runtime overhead of the user applications to a minimum while enforcing
common developer best practices and other organizational conventions.
\item Design and implement a methodology for formulating performance SLOs for cloud-hosted 
 web applications, without
 subjecting them to extensive performance testing or instrumentation. The formulated
 performance SLOs must be correct, tight and durable in the face of changing
 conditions of the cloud.
 \item Design and implement a scalable cloud application monitoring framework for detecting
application performance anomalies, SLO violations and diagnosing potential root causes. 
The framework should support collecting
 a wide range of performance and usage data from the user applications and the underlying cloud platform
 without instrumenting the user code, and without introducing significant runtime overheads.
 It should further facilitate employing a number of new and existing statistical methods
 and algorithms to analyze the gathered data in near realtime.
\end{enumerate}

We design and implement EAGER~\cite{6903538, eager-fop15} as a means of 
achieving the first goal. EAGER is a lightweight
governance framework built into PaaS clouds. It supports defining policies using a simple syntax
based on the popular Python programming language. EAGER promotes deployment-time
policy enforcement, where policies are enforced on user applications (and APIs) every time
an application is uploaded to the cloud. By carrying out policy validations at
application deployment-time, and refusing to deploy applications that violate policies,
 we provide fail-fast semantics which ensure that deployed applications are fully policy compliant. 
EAGER architecture also provides the necessary provisions for facilitating run-time policy
enforcement (through an API gateway proxy) if necessary. Our experimental results show
that EAGER validation and policy enforcement overhead is negligibly small, and it scales well to
handle thousands of user applications and policies. Overall, we show that integrated governance
for cloud-hosted applications is not only feasible, but also can be implemented with very
little overhead and effort.

To achieve the second goal of formulating performance SLOs, we design and implement 
Cerebro~\cite{Jayathilaka:2015:RTS:2806777.2806842} --
a system that can predict bounds on the response time of web applications developed for PaaS clouds.
Cerebro is able to analyze a given web application, and determine a bound on its response time without
subjecting the application to any testing or runtime instrumentation. This is achieved by a mechanism
that combines static analysis of application source code with runtime monitoring of the underlying
cloud platform (PaaS SDK to be specific). Our approach is limited to interactive web applications
developed using a PaaS SDK. We show that such applications have very few branches and loops, 
and they spend most of their execution time invoking PaaS SDK operations. These properties
make the applications amenable to both static analysis, and statistical treatment of their 
performance limits.

Cerebro is fast, can be invoked at the deployment-time 
of an application, and does not require any human input or intervention. 
The bounds predicted by Cerebro can be used as statistical guarantees (with well defined correctness
probabilities) to form performance SLOs. These SLOs in turns can be used in SLAs that are negotiated
with the users of the web applications. Cerebro's SLO prediction capability, coupled with a policy
enforcement framework such as EAGER, can facilitate specification and enforcement of performance-related
policies for cloud-hosted applications. We implement Cerebro for Google App Engine public cloud
and AppScale private cloud. Our experiments with real world PaaS applications show that Cerebro
is able to determine accurate performance SLOs that closely reflect the actual response time
of the applications. Furthermore, we show that Cerebro predicted SLOs are not easily affected by
the dynamic nature of the cloud platform, and they remain valid for long durations. More specifically, 
Cerebro predictions remain correct for more than 12 days on average~\cite{7396174}. 

Finally, we design and implement Roots to address our third goal. Roots is a performance anomaly detection and 
bottleneck identification system built into PaaS clouds. It collects data from all the different layers of the
PaaS stack -- from load balancers to low level PaaS kernel service implementations. However,
it does so efficiently, without instrumenting user code, and without introducing a significant
overhead to the application request processing flow. 
Roots uses the metadata (request identifiers) injected by the load balancers to correlate the
events observed in different layers, 
thereby enabling tracing of application requests through the PaaS stack.
Roots is also extensible in the sense that 
any number of statistical analysis methods can be incorporated into Roots for performance
anomaly detection and diagnosis. Furthermore, it facilitates configuring monitoring requirements
at the granularity of user applications, which allows different applications to be monitored
and analyzed differently. 

Roots detects performance anomalies by monitoring applications for SLO violations. 
When an anomaly (i.e. an SLO violation) is detected, Roots is able to determine if
the anomaly was caused by a change in the application workload or by a performance 
bottleneck in one of the underlying PaaS kernel services. To this end we present a mechanism
that uses a combination of linear regression, change point detection and quantile analysis to
perform root cause analysis. We show that our combined approach makes correct diagnoses nearly
100\% of the time. Finally, we also present a path distribution analyzer that can identify different
paths of execution in an application via the run-time data gathered from the cloud platform.
We show that this mechanism is capable of detecting characteristic changes in application
workload as a special type of anomalies. Our design of Roots also consists of a component
that can detect quantitative changes in application workload.