/*
 *  Licensed to the Apache Software Foundation (ASF) under one
 *  or more contributor license agreements.  See the NOTICE file
 *  distributed with this work for additional information
 *  regarding copyright ownership.  The ASF licenses this file
 *  to you under the Apache License, Version 2.0 (the
 *  "License"); you may not use this file except in compliance
 *  with the License.  You may obtain a copy of the License at
 *
 *   http://www.apache.org/licenses/LICENSE-2.0
 *
 *  Unless required by applicable law or agreed to in writing,
 *  software distributed under the License is distributed on an
 *   * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 *  KIND, either express or implied.  See the License for the
 *  specific language governing permissions and limitations
 *  under the License.
 */

package edu.ucsb.cs.eager.sa.kitty;

import org.apache.commons.cli.*;

import java.io.*;
import java.util.*;

/**
 * Kitty analyzes trace files generated by Cerebro and makes
 * predictions regarding the timing of the function calls. It picks
 * the worst-case paths from Cerebro traces and predicts their
 * execution time. Kitty is named after Kitty Pryde, for her ability of
 * phasing through the currents of time.
 */
public class Kitty {

    public static void main(String[] args) throws IOException {
        Options options = new Options();
        options.addOption("i", "input-file", true,
                "Path to the Cerebro trace file");
        options.addOption("b", "benchmark-dir", true,
                "Path to the directory containing seed benchmark results");
        options.addOption("sn", "simulations", true,
                "Number of times to simulate each path (default 100)");
        options.addOption("s", "benchmark-svc", true,
                "URL of the benchmark data service");

        CommandLine cmd;
        try {
            CommandLineParser parser = new BasicParser();
            cmd = parser.parse( options, args);
        } catch (ParseException e) {
            System.err.println("Error: " + e.getMessage() + "\n");
            HelpFormatter formatter = new HelpFormatter();
            formatter.printHelp("Kitty", options);
            return;
        }

        PredictionConfig config = new PredictionConfig();
        config.traceFile = cmd.getOptionValue("i");
        config.benchmarkDataDir = cmd.getOptionValue("b");
        String sn = cmd.getOptionValue("sn");
        if (sn != null) {
            config.simulations = Integer.parseInt(sn);
        }
        config.benchmarkDataSvc = cmd.getOptionValue("s");

        try {
            config.validate();
        } catch (Exception e) {
            System.err.println(e.getMessage());
            return;
        }

        Kitty k = new Kitty();
        if (config.benchmarkDataDir != null) {
            k.predictBySimulation(config);
        }
    }

    public void predictBySimulation(PredictionConfig config) throws IOException {
        Map<String,TimingDistribution> benchmarkResults = loadBenchmarkDataFromDir(
                config.benchmarkDataDir);
        System.out.println("Running " + config.simulations + " simulations...\n");

        List<MethodInfo> methods = parseTraceFile(config.traceFile);
        for (MethodInfo m : methods) {
            System.out.println(m.getName());
            for (int i = 0; i < m.getName().length(); i++) {
                System.out.print("=");
            }
            System.out.println();
            System.out.println("Total paths: " + m.getPaths().size());
            System.out.println("Worst-case exec time: " + predictExecTime(m,
                    benchmarkResults, config.simulations));
            System.out.println();
        }
    }

    private List<MethodInfo> parseTraceFile(String traceFile) throws IOException {
        BufferedReader reader = new BufferedReader(new FileReader(traceFile));
        TraceLogParser parser = new TraceLogParser();
        String line;
        try {
            while ((line = reader.readLine()) != null) {
                parser.parse(line);
            }
        } finally {
            reader.close();
        }
        return parser.getMethods();
    }

    private Map<String,TimingDistribution> loadBenchmarkDataFromDir(
            String benchmarkDir) throws IOException {
        File dir = new File(benchmarkDir);
        File[] dataFiles = dir.listFiles(new FilenameFilter() {
            @Override
            public boolean accept(File dir, String name) {
                return name.endsWith(".txt");
            }
        });
        Map<String,TimingDistribution> benchmarkResults = new HashMap<String, TimingDistribution>();
        if (dataFiles.length > 0) {
            for (File f : dataFiles) {
                TimingDistribution dist = new TimingDistribution(f);
                benchmarkResults.put(dist.getApiCall(), dist);
            }
            System.out.println();
        }
        return benchmarkResults;
    }

    private Prediction predictExecTime(MethodInfo method, Map<String,TimingDistribution> bm,
                                      int simulations) {
        List<List<APICall>> pathsOfInterest = new ArrayList<List<APICall>>();
        for (List<APICall> p : method.getPaths()) {
            if (p.size() == 1 && p.get(0).getName().equals("-- No API Calls --")) {
                continue;
            }
            pathsOfInterest.add(p);
        }

        if (pathsOfInterest.size() == 0) {
            return new Prediction("No paths with API calls found");
        } else {
            Prediction[] predictions = new Prediction[pathsOfInterest.size()];
            // Simulate each path
            for (int i = 0; i < pathsOfInterest.size(); i++) {
                predictions[i] = simulatePath(pathsOfInterest.get(i), bm, simulations);
            }
            // And return the most expensive one
            Prediction max = new Prediction(0.0);
            for (int i = 0; i < pathsOfInterest.size(); i++) {
                if (predictions[i].mean > max.mean) {
                    max = predictions[i];
                }
            }
            return max;
        }
    }

    private Prediction simulatePath(List<APICall> path, Map<String,TimingDistribution> bm,
                                    int simulations) {
        double[] results = new double[simulations];
        for (int i = 0; i < simulations; i++) {
            double total = 0.0;
            for (APICall call : path) {
                if (bm.containsKey(call.getShortName())) {
                    total += bm.get(call.getShortName()).sample();
                } else {
                    throw new RuntimeException("No benchmark data available for: " + call.getName());
                }
            }
            results[i] = total;
        }

        double total = 0.0;
        for (double r : results) {
            total += r;
        }
        return new Prediction(total / simulations);
    }

    private static class Prediction {
        private String msg;
        private double mean;

        private Prediction(String msg) {
            this.msg = msg;
        }

        private Prediction(double mean) {
            this.mean = mean;
        }

        @Override
        public String toString() {
            if (msg != null) {
                return msg;
            }
            return String.format("%.4fms", mean);
        }
    }

    private static class PredictionConfig {
        /**
         * Path to a directory containing API benchmark results.
         */
        private String benchmarkDataDir;
        /**
         * Number of simulations to run.
         */
        private int simulations = 100;

        /**
         * URL of the benchmark data service.
         */
        private String benchmarkDataSvc;
        /**
         * Whether the predictions should be made by aggregating
         * multiple time series data into a single time series.
         */
        private boolean aggregateTimeSeries;

        /**
         * Path to an existing Cerebro trace file, from which the
         * program execution paths can be extracted.
         */
        private String traceFile;

        void validate() throws Exception {
            if (benchmarkDataDir == null && benchmarkDataSvc == null) {
                throw new Exception("One of benchmark data directory and benchmark data service" +
                        " must be specified.");
            } else if (benchmarkDataDir != null && benchmarkDataSvc != null) {
                throw new Exception("Both benchmark data directory and benchmark data service" +
                        " should not be specified.");
            } else if (traceFile == null) {
                throw new Exception("Trace file path must be specified.");
            }
        }
    }
}
